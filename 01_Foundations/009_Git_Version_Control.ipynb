{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 009: Git & Version Control Mastery\n",
    "\n",
    "## \ud83c\udfaf Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- **Master** Branching strategies\n",
    "- **Master** Merge vs rebase\n",
    "- **Master** Pull requests and code review\n",
    "- **Master** CI/CD integration\n",
    "- **Master** Model versioning with DVC\n",
    "\n",
    "## \ud83d\udcda Overview\n",
    "\n",
    "This notebook covers Git & Version Control Mastery essential for AI/ML engineering.\n",
    "\n",
    "**Post-silicon applications**: Optimized data pipelines, efficient algorithms, scalable systems.\n",
    "\n",
    "---\n",
    "\n",
    "Let's dive in! \ud83d\ude80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcda What is Git & Version Control?\n",
    "\n",
    "**Version control** is a system that records changes to files over time, enabling you to recall specific versions, collaborate effectively, and maintain code quality. **Git** is the de facto standard distributed version control system used by 95% of software teams worldwide.\n",
    "\n",
    "**Why Git for AI/ML?**\n",
    "- \u2705 **Collaboration**: 10-100 engineers working on same codebase (Intel: 250+ engineers on AI platform)\n",
    "- \u2705 **Reproducibility**: Track exact code version that trained a model (NVIDIA: \"Which commit produced model v2.3?\")\n",
    "- \u2705 **Experimentation**: Branch for experiments without breaking production (AMD: 50+ feature branches active)\n",
    "- \u2705 **Code Review**: Pull requests ensure quality before merge (Qualcomm: 98% bugs caught in review)\n",
    "- \u2705 **Rollback**: Instantly revert bad deployments (Meta: rollback in <5 minutes)\n",
    "\n",
    "**Version Control != Just Git:**\n",
    "- **Code**: Git tracks `.py`, `.ipynb`, config files\n",
    "- **Data**: DVC (Data Version Control) tracks datasets, models (>100MB files)\n",
    "- **Experiments**: MLflow tracks hyperparameters, metrics, artifacts\n",
    "- **Models**: Model registry (MLflow, SageMaker) tracks production models\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udfed Post-Silicon Validation Use Cases\n",
    "\n",
    "**1. Intel Test Program Development**\n",
    "- **Scenario**: 50 engineers developing test programs for 20 products\n",
    "- **Challenge**: Conflicting changes, untested code reaching production\n",
    "- **Solution**: Git Flow with feature branches + CI/CD + mandatory code review\n",
    "- **Input**: Test programs in C/Python, configuration files, golden data\n",
    "- **Output**: 95% fewer production bugs, 40% faster development\n",
    "- **Value**: $8M saved annually (reduced test escapes, faster time-to-market)\n",
    "\n",
    "**2. NVIDIA Model Training Workflows**\n",
    "- **Scenario**: 30 data scientists experimenting with 100+ model variants\n",
    "- **Challenge**: \"Which hyperparameters produced this model? Which data version?\"\n",
    "- **Solution**: DVC for data/models + Git for code + MLflow for experiments\n",
    "- **Input**: Training code, datasets (500GB), model checkpoints (2GB each)\n",
    "- **Output**: Full reproducibility, rollback to any experiment in <5 min\n",
    "- **Value**: $5M saved (reproducible research, regulatory compliance)\n",
    "\n",
    "**3. AMD Automated Testing Pipeline**\n",
    "- **Scenario**: Every code commit must pass 10K tests before merge\n",
    "- **Challenge**: Manual testing takes 8 hours, blocks development\n",
    "- **Solution**: GitHub Actions CI/CD pipeline (test on every PR)\n",
    "- **Input**: Pull request with code changes\n",
    "- **Output**: Automated testing, quality gates, deployment to staging\n",
    "- **Value**: $12M saved (8 hours \u2192 30 minutes, 99.5% bug detection before production)\n",
    "\n",
    "**4. Qualcomm Multi-Site Collaboration**\n",
    "- **Scenario**: Engineers in San Diego, India, China collaborating on ML platform\n",
    "- **Challenge**: Time zone conflicts, code conflicts, duplicate work\n",
    "- **Solution**: Trunk-based development + feature flags + daily integration\n",
    "- **Input**: 200+ commits/day from 3 continents\n",
    "- **Output**: Zero merge conflicts, continuous integration, <1 day feedback\n",
    "- **Value**: $10M saved (3\u00d7 development velocity, eliminated duplicate work)\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udd04 Git Workflow Comparison\n",
    "\n",
    "```mermaid\n",
    "graph TB\n",
    "    subgraph \"Git Flow\"\n",
    "        A1[main] --> B1[develop]\n",
    "        B1 --> C1[feature/login]\n",
    "        B1 --> C2[feature/api]\n",
    "        C1 --> B1\n",
    "        C2 --> B1\n",
    "        B1 --> D1[release/v1.0]\n",
    "        D1 --> A1\n",
    "        A1 --> E1[hotfix/bug]\n",
    "        E1 --> A1\n",
    "    end\n",
    "    \n",
    "    subgraph \"Trunk-Based\"\n",
    "        A2[main] --> B2[feature/short-lived]\n",
    "        B2 --> A2\n",
    "        A2 --> C2[Deploy]\n",
    "    end\n",
    "    \n",
    "    style A1 fill:#e1ffe1\n",
    "    style A2 fill:#e1ffe1\n",
    "    style C2 fill:#ffe1e1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcca Learning Path Context\n",
    "\n",
    "**Prerequisites:**\n",
    "- None (foundational skill for all ML engineering)\n",
    "- Basic command line experience helpful\n",
    "\n",
    "**Next Steps:**\n",
    "- **010: Linear Regression** - Apply Git to track ML experiments\n",
    "- **048: Model Deployment** - CI/CD for model serving\n",
    "- **111: MLOps Fundamentals** - End-to-end ML pipelines with version control\n",
    "\n",
    "**Related Skills:**\n",
    "- Docker (containerization for reproducible environments)\n",
    "- CI/CD tools (GitHub Actions, Jenkins, GitLab CI)\n",
    "- DVC (data version control for large datasets/models)\n",
    "\n",
    "---\n",
    "\n",
    "Let's master Git & Version Control for production ML systems! \ud83d\ude80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Git Fundamentals & Branching Strategies\n",
    "\n",
    "### Core Git Concepts\n",
    "\n",
    "**Repository Structure:**\n",
    "```\n",
    ".git/\n",
    "\u251c\u2500\u2500 HEAD              # Points to current branch\n",
    "\u251c\u2500\u2500 refs/\n",
    "\u2502   \u251c\u2500\u2500 heads/        # Local branches\n",
    "\u2502   \u2514\u2500\u2500 remotes/      # Remote branches\n",
    "\u251c\u2500\u2500 objects/          # All commits, trees, blobs\n",
    "\u2514\u2500\u2500 config            # Repository configuration\n",
    "```\n",
    "\n",
    "**Three States of Git:**\n",
    "1. **Working Directory**: Modified files not yet staged\n",
    "2. **Staging Area (Index)**: Files ready to commit\n",
    "3. **Repository**: Committed snapshots\n",
    "\n",
    "**Essential Commands:**\n",
    "```bash\n",
    "# Initialize & clone\n",
    "git init                              # Create new repo\n",
    "git clone <url>                       # Clone existing repo\n",
    "\n",
    "# Daily workflow\n",
    "git status                            # Check file states\n",
    "git add <file>                        # Stage changes\n",
    "git commit -m \"message\"               # Commit staged changes\n",
    "git push origin <branch>              # Push to remote\n",
    "git pull origin <branch>              # Pull from remote\n",
    "\n",
    "# Branching\n",
    "git branch <name>                     # Create branch\n",
    "git checkout <name>                   # Switch branch\n",
    "git checkout -b <name>                # Create + switch\n",
    "git merge <branch>                    # Merge branch\n",
    "git rebase <branch>                   # Rebase onto branch\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Branching Strategies Comparison\n",
    "\n",
    "#### 1. **Git Flow** (Complex Projects)\n",
    "\n",
    "**Structure:**\n",
    "- `main`: Production-ready code (always deployable)\n",
    "- `develop`: Integration branch (active development)\n",
    "- `feature/*`: New features (branch from develop)\n",
    "- `release/*`: Release preparation (branch from develop)\n",
    "- `hotfix/*`: Emergency fixes (branch from main)\n",
    "\n",
    "**When to use:**\n",
    "- \u2705 Scheduled releases (quarterly, monthly)\n",
    "- \u2705 Multiple versions in production\n",
    "- \u2705 Large teams (50+ engineers)\n",
    "- \u2705 High stability requirements\n",
    "\n",
    "**Intel Example:**\n",
    "- 250 engineers, 20 products\n",
    "- `main`: Released silicon test programs\n",
    "- `develop`: Next-generation features\n",
    "- `feature/ddr5-test`: New DDR5 memory tests\n",
    "- `release/2024.Q1`: Stabilize for Q1 release\n",
    "- `hotfix/critical-bug`: Fix production issue\n",
    "- **Result**: 95% fewer production bugs, clear release process\n",
    "\n",
    "#### 2. **Trunk-Based Development** (Fast-Moving Teams)\n",
    "\n",
    "**Structure:**\n",
    "- `main`: Single source of truth (always deployable)\n",
    "- Short-lived feature branches (<2 days)\n",
    "- Feature flags for incomplete features\n",
    "- Continuous integration + daily commits\n",
    "\n",
    "**When to use:**\n",
    "- \u2705 Continuous deployment (10+ deploys/day)\n",
    "- \u2705 Small teams (5-15 engineers)\n",
    "- \u2705 Fast iteration required\n",
    "- \u2705 Strong CI/CD pipeline\n",
    "\n",
    "**Qualcomm Example:**\n",
    "- 15 ML engineers, deploy 3\u00d7/day\n",
    "- All work in `main` or 1-day feature branches\n",
    "- Feature flags hide incomplete features\n",
    "- Automated tests run on every commit\n",
    "- **Result**: 3\u00d7 development velocity, zero merge conflicts\n",
    "\n",
    "#### 3. **GitHub Flow** (Simple Projects)\n",
    "\n",
    "**Structure:**\n",
    "- `main`: Always deployable\n",
    "- Feature branches for all work\n",
    "- Pull requests for code review\n",
    "- Deploy after merge\n",
    "\n",
    "**When to use:**\n",
    "- \u2705 Web apps, APIs (continuous deployment)\n",
    "- \u2705 Small/medium teams\n",
    "- \u2705 Simple release process\n",
    "- \u2705 GitHub-centric workflow\n",
    "\n",
    "**NVIDIA Example:**\n",
    "- 30 data scientists training models\n",
    "- Branch for each experiment\n",
    "- Pull request + peer review\n",
    "- Auto-deploy to staging after merge\n",
    "- **Result**: High quality code, fast experimentation\n",
    "\n",
    "---\n",
    "\n",
    "### Merge vs Rebase\n",
    "\n",
    "**Merge:**\n",
    "```bash\n",
    "git checkout main\n",
    "git merge feature\n",
    "# Creates merge commit, preserves history\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- \u2705 Preserves complete history\n",
    "- \u2705 Non-destructive (safe)\n",
    "- \u2705 Clear feature integration point\n",
    "\n",
    "**Cons:**\n",
    "- \u274c Messy history with many branches\n",
    "- \u274c Harder to understand timeline\n",
    "\n",
    "**Rebase:**\n",
    "```bash\n",
    "git checkout feature\n",
    "git rebase main\n",
    "# Replays commits on top of main\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- \u2705 Linear, clean history\n",
    "- \u2705 Easy to understand\n",
    "- \u2705 Simplifies code review\n",
    "\n",
    "**Cons:**\n",
    "- \u274c Rewrites history (dangerous if shared)\n",
    "- \u274c Conflicts must be resolved per commit\n",
    "\n",
    "**Best Practice:**\n",
    "- **Rebase**: Private feature branches (clean up before PR)\n",
    "- **Merge**: Public branches (preserve collaboration history)\n",
    "- **AMD Rule**: \"Rebase locally, merge remotely\"\n",
    "\n",
    "---\n",
    "\n",
    "### Post-Silicon Branching Patterns\n",
    "\n",
    "**Pattern 1: Test Program Development (Intel)**\n",
    "```\n",
    "main (production test programs)\n",
    "\u251c\u2500\u2500 develop (next release)\n",
    "\u2502   \u251c\u2500\u2500 feature/memory-stress-test\n",
    "\u2502   \u251c\u2500\u2500 feature/power-optimization\n",
    "\u2502   \u2514\u2500\u2500 feature/thermal-monitoring\n",
    "\u251c\u2500\u2500 release/v2024.1 (stabilization)\n",
    "\u2514\u2500\u2500 hotfix/voltage-bug (critical fix)\n",
    "```\n",
    "\n",
    "**Pattern 2: Model Experiments (NVIDIA)**\n",
    "```\n",
    "main (production models)\n",
    "\u251c\u2500\u2500 experiment/transformer-v2 (1-day branch)\n",
    "\u251c\u2500\u2500 experiment/quantization (2-day branch)\n",
    "\u2514\u2500\u2500 experiment/distillation (3-day branch)\n",
    "```\n",
    "\n",
    "**Pattern 3: Data Pipeline (AMD)**\n",
    "```\n",
    "main (production pipeline)\n",
    "\u251c\u2500\u2500 feature/real-time-ingestion (long-running)\n",
    "\u251c\u2500\u2500 feature/new-data-source (short-lived)\n",
    "\u2514\u2500\u2500 hotfix/memory-leak (emergency)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Simulate Git workflows (branching, merging, rebasing) to understand version control patterns\n",
    "\n",
    "**Key Points:**\n",
    "- **Repository Class**: Simulates Git operations (commit, branch, merge, rebase)\n",
    "- **Commit Graph**: Maintains parent-child relationships between commits\n",
    "- **Branching**: Track multiple development lines simultaneously\n",
    "- **Merge vs Rebase**: Visualize history differences\n",
    "\n",
    "**Intel Example**: 250 engineers use Git Flow with feature branches. Simulation demonstrates how commits integrate, helping new engineers understand branching strategies before real work.\n",
    "\n",
    "**Why This Matters:** Understanding Git internals prevents merge conflicts, enables efficient collaboration, and ensures code quality through proper workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Set, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "\n",
    "@dataclass\n",
    "class Commit:\n",
    "    \"\"\"Represents a Git commit\"\"\"\n",
    "    hash: str\n",
    "    message: str\n",
    "    parents: List[str] = field(default_factory=list)\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "    author: str = \"engineer@company.com\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        parent_info = f\" (parents: {', '.join(self.parents[:2])})\" if self.parents else \"\"\n",
    "        return f\"{self.hash[:7]}: {self.message}{parent_info}\"\n",
    "\n",
    "class GitRepository:\n",
    "    \"\"\"Simulates Git repository operations\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.commits: Dict[str, Commit] = {}\n",
    "        self.branches: Dict[str, str] = {}  # branch_name -> commit_hash\n",
    "        self.current_branch = \"main\"\n",
    "        \n",
    "        # Create initial commit\n",
    "        initial = self._create_commit(\"Initial commit\", [])\n",
    "        self.branches[\"main\"] = initial.hash\n",
    "    \n",
    "    def _create_commit(self, message: str, parents: List[str]) -> Commit:\n",
    "        \"\"\"Create a new commit\"\"\"\n",
    "        # Generate hash from message + parents\n",
    "        content = f\"{message}{''.join(parents)}{datetime.now().isoformat()}\"\n",
    "        commit_hash = hashlib.md5(content.encode()).hexdigest()\n",
    "        \n",
    "        commit = Commit(hash=commit_hash, message=message, parents=parents)\n",
    "        self.commits[commit_hash] = commit\n",
    "        return commit\n",
    "    \n",
    "    def commit(self, message: str) -> str:\n",
    "        \"\"\"Create commit on current branch\"\"\"\n",
    "        parent_hash = self.branches[self.current_branch]\n",
    "        commit = self._create_commit(message, [parent_hash])\n",
    "        self.branches[self.current_branch] = commit.hash\n",
    "        return commit.hash\n",
    "    \n",
    "    def branch(self, branch_name: str, from_branch: Optional[str] = None) -> None:\n",
    "        \"\"\"Create new branch\"\"\"\n",
    "        source = from_branch or self.current_branch\n",
    "        if source not in self.branches:\n",
    "            raise ValueError(f\"Branch {source} does not exist\")\n",
    "        \n",
    "        self.branches[branch_name] = self.branches[source]\n",
    "        print(f\"\u2713 Created branch '{branch_name}' from '{source}' at {self.branches[source][:7]}\")\n",
    "    \n",
    "    def checkout(self, branch_name: str) -> None:\n",
    "        \"\"\"Switch to branch\"\"\"\n",
    "        if branch_name not in self.branches:\n",
    "            raise ValueError(f\"Branch {branch_name} does not exist\")\n",
    "        \n",
    "        self.current_branch = branch_name\n",
    "        print(f\"\u2713 Switched to branch '{branch_name}'\")\n",
    "    \n",
    "    def merge(self, branch_name: str) -> str:\n",
    "        \"\"\"Merge branch into current branch\"\"\"\n",
    "        if branch_name not in self.branches:\n",
    "            raise ValueError(f\"Branch {branch_name} does not exist\")\n",
    "        \n",
    "        current_hash = self.branches[self.current_branch]\n",
    "        merge_hash = self.branches[branch_name]\n",
    "        \n",
    "        # Create merge commit with two parents\n",
    "        commit = self._create_commit(\n",
    "            f\"Merge branch '{branch_name}' into {self.current_branch}\",\n",
    "            [current_hash, merge_hash]\n",
    "        )\n",
    "        self.branches[self.current_branch] = commit.hash\n",
    "        print(f\"\u2713 Merged '{branch_name}' into '{self.current_branch}' (merge commit: {commit.hash[:7]})\")\n",
    "        return commit.hash\n",
    "    \n",
    "    def rebase(self, onto_branch: str) -> None:\n",
    "        \"\"\"Rebase current branch onto another branch\"\"\"\n",
    "        if onto_branch not in self.branches:\n",
    "            raise ValueError(f\"Branch {onto_branch} does not exist\")\n",
    "        \n",
    "        # Simplified rebase: just move branch pointer\n",
    "        # In real Git, this would replay commits\n",
    "        self.branches[self.current_branch] = self.branches[onto_branch]\n",
    "        print(f\"\u2713 Rebased '{self.current_branch}' onto '{onto_branch}'\")\n",
    "    \n",
    "    def log(self, branch: Optional[str] = None, limit: int = 10) -> List[Commit]:\n",
    "        \"\"\"Show commit history\"\"\"\n",
    "        target_branch = branch or self.current_branch\n",
    "        if target_branch not in self.branches:\n",
    "            raise ValueError(f\"Branch {target_branch} does not exist\")\n",
    "        \n",
    "        history = []\n",
    "        visited = set()\n",
    "        to_visit = [self.branches[target_branch]]\n",
    "        \n",
    "        while to_visit and len(history) < limit:\n",
    "            commit_hash = to_visit.pop(0)\n",
    "            if commit_hash in visited:\n",
    "                continue\n",
    "            \n",
    "            visited.add(commit_hash)\n",
    "            commit = self.commits[commit_hash]\n",
    "            history.append(commit)\n",
    "            \n",
    "            # Add parents to visit\n",
    "            to_visit.extend(commit.parents)\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def status(self) -> None:\n",
    "        \"\"\"Show repository status\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Repository: {self.name}\")\n",
    "        print(f\"Current branch: {self.current_branch}\")\n",
    "        print(f\"Latest commit: {self.branches[self.current_branch][:7]}\")\n",
    "        print(f\"\\nBranches:\")\n",
    "        for branch, commit_hash in sorted(self.branches.items()):\n",
    "            marker = \"* \" if branch == self.current_branch else \"  \"\n",
    "            commit = self.commits[commit_hash]\n",
    "            print(f\"{marker}{branch:20} {commit_hash[:7]} {commit.message}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "# Demonstration: Intel Git Flow Workflow\n",
    "print(\"=\" * 70)\n",
    "print(\"INTEL GIT FLOW SIMULATION\")\n",
    "print(\"Scenario: 3 engineers developing test programs for DDR5 memory\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Initialize repository\n",
    "intel_repo = GitRepository(\"intel-test-programs\")\n",
    "intel_repo.status()\n",
    "\n",
    "# Create develop branch\n",
    "intel_repo.branch(\"develop\", \"main\")\n",
    "intel_repo.checkout(\"develop\")\n",
    "intel_repo.commit(\"Setup test framework\")\n",
    "intel_repo.commit(\"Add base DDR5 test class\")\n",
    "\n",
    "# Engineer 1: Memory stress test\n",
    "intel_repo.branch(\"feature/memory-stress\", \"develop\")\n",
    "intel_repo.checkout(\"feature/memory-stress\")\n",
    "intel_repo.commit(\"Add memory stress patterns\")\n",
    "intel_repo.commit(\"Implement address scrambling\")\n",
    "intel_repo.commit(\"Add temperature monitoring\")\n",
    "\n",
    "# Engineer 2: Power optimization\n",
    "intel_repo.checkout(\"develop\")\n",
    "intel_repo.branch(\"feature/power-optimization\", \"develop\")\n",
    "intel_repo.checkout(\"feature/power-optimization\")\n",
    "intel_repo.commit(\"Measure baseline power consumption\")\n",
    "intel_repo.commit(\"Optimize voltage transitions\")\n",
    "\n",
    "# Engineer 3: Data integrity checks\n",
    "intel_repo.checkout(\"develop\")\n",
    "intel_repo.branch(\"feature/data-integrity\", \"develop\")\n",
    "intel_repo.checkout(\"feature/data-integrity\")\n",
    "intel_repo.commit(\"Implement ECC validation\")\n",
    "intel_repo.commit(\"Add bit flip detection\")\n",
    "\n",
    "print(\"\\n\ud83d\udcca Status after feature development:\")\n",
    "intel_repo.status()\n",
    "\n",
    "# Merge features back to develop\n",
    "intel_repo.checkout(\"develop\")\n",
    "print(\"\\n\ud83d\udd00 Merging features into develop:\")\n",
    "intel_repo.merge(\"feature/memory-stress\")\n",
    "intel_repo.merge(\"feature/power-optimization\")\n",
    "intel_repo.merge(\"feature/data-integrity\")\n",
    "\n",
    "# Create release branch\n",
    "intel_repo.branch(\"release/v2024.1\", \"develop\")\n",
    "intel_repo.checkout(\"release/v2024.1\")\n",
    "intel_repo.commit(\"Update version to 2024.1\")\n",
    "intel_repo.commit(\"Final testing and bug fixes\")\n",
    "\n",
    "# Merge to main (production)\n",
    "intel_repo.checkout(\"main\")\n",
    "intel_repo.merge(\"release/v2024.1\")\n",
    "\n",
    "print(\"\\n\u2705 Final repository state:\")\n",
    "intel_repo.status()\n",
    "\n",
    "print(\"\\n\ud83d\udcdc Commit history on main:\")\n",
    "for commit in intel_repo.log(\"main\", limit=15):\n",
    "    print(f\"  {commit}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESULT: 3 features integrated successfully with no conflicts!\")\n",
    "print(\"Git Flow ensures: \u2713 Isolated development \u2713 Code review \u2713 Stable releases\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: CI/CD & Automated Testing\n",
    "\n",
    "### Continuous Integration/Continuous Deployment\n",
    "\n",
    "**CI/CD Pipeline Flow:**\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[Push Code] --> B[Run Tests]\n",
    "    B --> C{Tests Pass?}\n",
    "    C -->|Yes| D[Build Artifact]\n",
    "    C -->|No| E[Notify Developer]\n",
    "    D --> F[Deploy to Staging]\n",
    "    F --> G[Integration Tests]\n",
    "    G --> H{Tests Pass?}\n",
    "    H -->|Yes| I[Deploy to Production]\n",
    "    H -->|No| E\n",
    "    \n",
    "    style A fill:#e1f5ff\n",
    "    style I fill:#e1ffe1\n",
    "    style E fill:#ffe1e1\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- \u2705 **Fast Feedback**: Know within 10 minutes if code breaks\n",
    "- \u2705 **Quality Gates**: Automated checks prevent bad code from merging\n",
    "- \u2705 **Consistent Builds**: Same environment every time\n",
    "- \u2705 **Reduced Manual Work**: Automate testing, deployment, monitoring\n",
    "\n",
    "---\n",
    "\n",
    "### GitHub Actions Workflow Example\n",
    "\n",
    "**AMD Test Pipeline** (`/.github/workflows/test.yml`):\n",
    "```yaml\n",
    "name: Test Pipeline\n",
    "\n",
    "on:\n",
    "  pull_request:\n",
    "    branches: [main, develop]\n",
    "  push:\n",
    "    branches: [main]\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    \n",
    "    steps:\n",
    "      - name: Checkout code\n",
    "        uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Setup Python\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: '3.10'\n",
    "      \n",
    "      - name: Install dependencies\n",
    "        run: |\n",
    "          pip install -r requirements.txt\n",
    "          pip install pytest pytest-cov flake8\n",
    "      \n",
    "      - name: Lint code\n",
    "        run: flake8 src/ --max-line-length=100\n",
    "      \n",
    "      - name: Run unit tests\n",
    "        run: pytest tests/ -v --cov=src --cov-report=xml\n",
    "      \n",
    "      - name: Check coverage\n",
    "        run: |\n",
    "          coverage report --fail-under=80\n",
    "      \n",
    "      - name: Upload coverage\n",
    "        uses: codecov/codecov-action@v3\n",
    "        with:\n",
    "          file: ./coverage.xml\n",
    "\n",
    "  integration:\n",
    "    needs: test\n",
    "    runs-on: ubuntu-latest\n",
    "    \n",
    "    steps:\n",
    "      - name: Checkout code\n",
    "        uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Run integration tests\n",
    "        run: |\n",
    "          docker-compose up -d\n",
    "          pytest tests/integration/ -v\n",
    "          docker-compose down\n",
    "```\n",
    "\n",
    "**AMD Results:**\n",
    "- \u23f1\ufe0f **Before**: 8 hours manual testing\n",
    "- \u26a1 **After**: 30 minutes automated pipeline\n",
    "- \ud83d\udcca **Coverage**: 85% code coverage (was 60%)\n",
    "- \ud83d\udcb0 **Savings**: $12M annually (faster releases, fewer bugs)\n",
    "\n",
    "---\n",
    "\n",
    "### Pre-commit Hooks (Quality Gates)\n",
    "\n",
    "**Qualcomm Pre-commit Configuration** (`/.pre-commit-config.yaml`):\n",
    "```yaml\n",
    "repos:\n",
    "  # Code formatting\n",
    "  - repo: https://github.com/psf/black\n",
    "    rev: 23.3.0\n",
    "    hooks:\n",
    "      - id: black\n",
    "        language_version: python3.10\n",
    "  \n",
    "  # Import sorting\n",
    "  - repo: https://github.com/PyCQA/isort\n",
    "    rev: 5.12.0\n",
    "    hooks:\n",
    "      - id: isort\n",
    "  \n",
    "  # Linting\n",
    "  - repo: https://github.com/PyCQA/flake8\n",
    "    rev: 6.0.0\n",
    "    hooks:\n",
    "      - id: flake8\n",
    "        args: [--max-line-length=100]\n",
    "  \n",
    "  # Type checking\n",
    "  - repo: https://github.com/pre-commit/mirrors-mypy\n",
    "    rev: v1.3.0\n",
    "    hooks:\n",
    "      - id: mypy\n",
    "        additional_dependencies: [types-requests]\n",
    "  \n",
    "  # Security checks\n",
    "  - repo: https://github.com/PyCQA/bandit\n",
    "    rev: 1.7.5\n",
    "    hooks:\n",
    "      - id: bandit\n",
    "        args: [-r, src/]\n",
    "  \n",
    "  # Notebook cleaning\n",
    "  - repo: https://github.com/kynan/nbstripout\n",
    "    rev: 0.6.1\n",
    "    hooks:\n",
    "      - id: nbstripout\n",
    "```\n",
    "\n",
    "**Installation:**\n",
    "```bash\n",
    "pip install pre-commit\n",
    "pre-commit install\n",
    "```\n",
    "\n",
    "**Qualcomm Impact:**\n",
    "- \u2713 98% of bugs caught before code review\n",
    "- \u2713 Zero formatting debates (Black enforces style)\n",
    "- \u2713 Security vulnerabilities blocked automatically\n",
    "- \u2713 Consistent code quality across 200 engineers\n",
    "\n",
    "---\n",
    "\n",
    "### Pull Request (PR) Best Practices\n",
    "\n",
    "**1. PR Structure (NVIDIA Template):**\n",
    "```markdown\n",
    "## Description\n",
    "Implement transformer model for quality prediction\n",
    "\n",
    "## Changes\n",
    "- Added transformer architecture (src/models/transformer.py)\n",
    "- Integrated attention mechanisms\n",
    "- Benchmarked against baseline (15% improvement)\n",
    "\n",
    "## Testing\n",
    "- Unit tests: 95% coverage\n",
    "- Integration tests: All pass\n",
    "- Performance: 50ms inference (baseline: 80ms)\n",
    "\n",
    "## Checklist\n",
    "- [x] Tests added/updated\n",
    "- [x] Documentation updated\n",
    "- [x] No linting errors\n",
    "- [x] Backward compatible\n",
    "```\n",
    "\n",
    "**2. Code Review Checklist:**\n",
    "- \u2705 **Functionality**: Does code work as intended?\n",
    "- \u2705 **Tests**: Adequate test coverage?\n",
    "- \u2705 **Readability**: Clear variable names, comments?\n",
    "- \u2705 **Performance**: No obvious bottlenecks?\n",
    "- \u2705 **Security**: No hardcoded secrets, SQL injection?\n",
    "- \u2705 **Maintainability**: Will future engineers understand this?\n",
    "\n",
    "**3. Review Etiquette:**\n",
    "- \ud83c\udfaf **Be specific**: \"Use `enumerate()` here for cleaner code\" vs \"This is bad\"\n",
    "- \ud83c\udfaf **Explain why**: \"This causes N+1 queries, consider eager loading\"\n",
    "- \ud83c\udfaf **Suggest alternatives**: \"Could we use caching here to reduce DB calls?\"\n",
    "- \ud83c\udfaf **Praise good code**: \"Great use of dataclasses here!\"\n",
    "\n",
    "**Intel PR Stats:**\n",
    "- \ud83d\udcca Average PR size: 200 lines (small, focused changes)\n",
    "- \u23f1\ufe0f Review time: <4 hours (fast feedback)\n",
    "- \ud83d\udd04 Iterations: 1.5 on average (high quality first submission)\n",
    "- \ud83d\udc1b Bugs caught: 95% before production\n",
    "\n",
    "---\n",
    "\n",
    "### CI/CD for ML Systems\n",
    "\n",
    "**NVIDIA Model Training Pipeline:**\n",
    "```yaml\n",
    "name: Model Training CI\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    paths:\n",
    "      - 'models/**'\n",
    "      - 'data/**'\n",
    "\n",
    "jobs:\n",
    "  train:\n",
    "    runs-on: gpu-runner  # Self-hosted with GPU\n",
    "    \n",
    "    steps:\n",
    "      - name: Checkout code\n",
    "        uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Setup DVC\n",
    "        run: |\n",
    "          pip install dvc[s3]\n",
    "          dvc pull  # Get data and models\n",
    "      \n",
    "      - name: Train model\n",
    "        run: |\n",
    "          python train.py --config configs/base.yaml\n",
    "      \n",
    "      - name: Evaluate model\n",
    "        run: |\n",
    "          python evaluate.py --threshold 0.85\n",
    "      \n",
    "      - name: Register model\n",
    "        if: success()\n",
    "        run: |\n",
    "          mlflow models register \\\n",
    "            --name quality_predictor \\\n",
    "            --model-uri runs:/${{ env.RUN_ID }}/model\n",
    "      \n",
    "      - name: Deploy to staging\n",
    "        if: success()\n",
    "        run: |\n",
    "          kubectl set image deployment/model-server \\\n",
    "            model=registry.nvidia.com/models:${{ github.sha }}\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "- \ud83c\udfaf **Automated Training**: Trigger on data/code changes\n",
    "- \ud83c\udfaf **Quality Gates**: Only deploy if accuracy >85%\n",
    "- \ud83c\udfaf **Model Registry**: Track all model versions\n",
    "- \ud83c\udfaf **Gradual Rollout**: Staging \u2192 Canary \u2192 Production\n",
    "\n",
    "**NVIDIA Results:**\n",
    "- Deploy 10 models/day (was 2/week)\n",
    "- 99.9% uptime (automated rollbacks)\n",
    "- $8M saved (faster iteration, fewer manual errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Data Version Control (DVC) for ML\n",
    "\n",
    "### Why DVC for Machine Learning?\n",
    "\n",
    "**The Problem:**\n",
    "- Git cannot handle large files (>100MB) efficiently\n",
    "- Datasets are 10GB-1TB, models are 100MB-10GB\n",
    "- Need reproducibility: \"Which data trained this model?\"\n",
    "\n",
    "**DVC Solution:**\n",
    "- Track data/models in Git (metadata only, ~1KB)\n",
    "- Store actual files in S3, GCS, Azure Blob\n",
    "- Version control for datasets and model artifacts\n",
    "- Reproduce any experiment from commit hash\n",
    "\n",
    "**DVC vs Git:**\n",
    "| Aspect | Git | DVC |\n",
    "|--------|-----|-----|\n",
    "| **File size** | <100MB | Unlimited |\n",
    "| **File types** | Code, configs | Data, models, artifacts |\n",
    "| **Storage** | .git folder | S3, GCS, Azure Blob |\n",
    "| **Version control** | Line-based | File-based (hash) |\n",
    "| **Speed** | Fast | Fast (only metadata in Git) |\n",
    "\n",
    "---\n",
    "\n",
    "### DVC Workflow (NVIDIA Example)\n",
    "\n",
    "**1. Initialize DVC:**\n",
    "```bash\n",
    "# Setup\n",
    "pip install dvc[s3]\n",
    "cd ml-project/\n",
    "git init\n",
    "dvc init\n",
    "\n",
    "# Configure remote storage\n",
    "dvc remote add -d myremote s3://nvidia-ml-data/experiments\n",
    "```\n",
    "\n",
    "**2. Track Data:**\n",
    "```bash\n",
    "# Add dataset (creates data.dvc metadata file)\n",
    "dvc add data/training_data.parquet\n",
    "git add data/training_data.parquet.dvc .gitignore\n",
    "git commit -m \"Add training data v1\"\n",
    "\n",
    "# Push data to S3\n",
    "dvc push\n",
    "```\n",
    "\n",
    "**3. Track Model:**\n",
    "```bash\n",
    "# Train model\n",
    "python train.py\n",
    "\n",
    "# Track model\n",
    "dvc add models/quality_predictor.h5\n",
    "git add models/quality_predictor.h5.dvc\n",
    "git commit -m \"Train model v1 (accuracy: 87.3%)\"\n",
    "dvc push\n",
    "```\n",
    "\n",
    "**4. Reproduce Experiment:**\n",
    "```bash\n",
    "# Colleague wants to reproduce\n",
    "git clone https://github.com/nvidia/ml-project.git\n",
    "cd ml-project/\n",
    "\n",
    "# Get data and model\n",
    "dvc pull\n",
    "\n",
    "# Same data + code = same results!\n",
    "python evaluate.py\n",
    "# Output: Accuracy: 87.3% \u2713\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### DVC Pipelines (AMD Example)\n",
    "\n",
    "**Define Pipeline** (`dvc.yaml`):\n",
    "```yaml\n",
    "stages:\n",
    "  prepare:\n",
    "    cmd: python prepare.py\n",
    "    deps:\n",
    "      - raw_data/wafer_tests.csv\n",
    "    params:\n",
    "      - prepare.train_split\n",
    "    outs:\n",
    "      - data/train.csv\n",
    "      - data/test.csv\n",
    "  \n",
    "  train:\n",
    "    cmd: python train.py\n",
    "    deps:\n",
    "      - data/train.csv\n",
    "      - train.py\n",
    "    params:\n",
    "      - train.learning_rate\n",
    "      - train.epochs\n",
    "    outs:\n",
    "      - models/model.pkl\n",
    "    metrics:\n",
    "      - metrics/train_metrics.json:\n",
    "          cache: false\n",
    "  \n",
    "  evaluate:\n",
    "    cmd: python evaluate.py\n",
    "    deps:\n",
    "      - data/test.csv\n",
    "      - models/model.pkl\n",
    "    metrics:\n",
    "      - metrics/eval_metrics.json:\n",
    "          cache: false\n",
    "```\n",
    "\n",
    "**Parameters** (`params.yaml`):\n",
    "```yaml\n",
    "prepare:\n",
    "  train_split: 0.8\n",
    "\n",
    "train:\n",
    "  learning_rate: 0.001\n",
    "  epochs: 100\n",
    "  batch_size: 32\n",
    "```\n",
    "\n",
    "**Run Pipeline:**\n",
    "```bash\n",
    "# Run entire pipeline\n",
    "dvc repro\n",
    "\n",
    "# DVC automatically:\n",
    "# 1. Checks what changed\n",
    "# 2. Runs only affected stages\n",
    "# 3. Caches intermediate results\n",
    "```\n",
    "\n",
    "**Experiment Tracking:**\n",
    "```bash\n",
    "# Try different hyperparameters\n",
    "dvc exp run -S train.learning_rate=0.01\n",
    "dvc exp run -S train.epochs=200\n",
    "\n",
    "# Compare experiments\n",
    "dvc exp show\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502 Experiment              \u2502 accuracy \u2502 f1_score  \u2502 lr      \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 workspace               \u2502 0.873    \u2502 0.865     \u2502 0.001   \u2502\n",
    "\u2502 exp-lr-001              \u2502 0.891    \u2502 0.883     \u2502 0.01    \u2502\n",
    "\u2502 exp-epochs-200          \u2502 0.885    \u2502 0.877     \u2502 0.001   \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**AMD Results:**\n",
    "- \ud83d\udcca **Reproducibility**: 100% (any experiment reproducible from Git commit)\n",
    "- \u26a1 **Speed**: 3\u00d7 faster experimentation (cached intermediate results)\n",
    "- \ud83d\udcbe **Storage**: $50K \u2192 $5K/year (deduplicated data, only store changes)\n",
    "- \ud83d\udd0d **Traceability**: Full lineage (data \u2192 model \u2192 predictions)\n",
    "\n",
    "---\n",
    "\n",
    "### Model Registry & Versioning\n",
    "\n",
    "**MLflow Model Registry (Intel):**\n",
    "```python\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Setup\n",
    "mlflow.set_tracking_uri(\"https://mlflow.intel.com\")\n",
    "mlflow.set_experiment(\"test_optimization\")\n",
    "\n",
    "# Train and log model\n",
    "with mlflow.start_run() as run:\n",
    "    # Train model\n",
    "    model = train_model(X_train, y_train)\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_params({\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"max_depth\": 10,\n",
    "        \"n_estimators\": 100\n",
    "    })\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\": 0.91,\n",
    "        \"test_accuracy\": 0.87,\n",
    "        \"f1_score\": 0.88\n",
    "    })\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    \n",
    "    # Register model\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "    mlflow.register_model(model_uri, \"test_optimizer\")\n",
    "\n",
    "# Transition to production\n",
    "client = MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=\"test_optimizer\",\n",
    "    version=3,\n",
    "    stage=\"Production\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Model Lifecycle:**\n",
    "```\n",
    "1. Development \u2192 2. Staging \u2192 3. Production \u2192 4. Archived\n",
    "   (experiment)     (validation)   (serving)      (retired)\n",
    "```\n",
    "\n",
    "**Intel Model Versioning Strategy:**\n",
    "- **v1.0.0** \u2192 Major: Architecture change (CNN \u2192 Transformer)\n",
    "- **v1.1.0** \u2192 Minor: Feature addition (new input signal)\n",
    "- **v1.1.1** \u2192 Patch: Bug fix (preprocessing correction)\n",
    "\n",
    "**Benefits:**\n",
    "- \u2705 Track all model versions (who, what, when, why)\n",
    "- \u2705 Compare models (accuracy, latency, size)\n",
    "- \u2705 Rollback instantly (production issue? Use v1.0.1)\n",
    "- \u2705 A/B testing (serve v1 to 70%, v2 to 30%)\n",
    "- \u2705 Audit trail (regulatory compliance, debugging)\n",
    "\n",
    "**Intel Results:**\n",
    "- \ud83d\ude80 Deploy models 5\u00d7 faster (automated pipeline)\n",
    "- \ud83d\udc1b Zero production incidents (thorough staging validation)\n",
    "- \ud83d\udcca Full experiment tracking (10K+ experiments tracked)\n",
    "- \ud83d\udcb0 $8M saved (reproducibility, faster debugging, compliance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Real-World Projects\n",
    "\n",
    "### Post-Silicon Validation Projects\n",
    "\n",
    "**1. Test Program Version Control System (Intel)**\n",
    "- **Objective**: Version control for 20 products \u00d7 500 test programs with CI/CD\n",
    "- **Architecture**:\n",
    "  - Git Flow branching (main/develop/feature/release/hotfix)\n",
    "  - GitHub Actions CI/CD (lint, test, deploy)\n",
    "  - DVC for golden data (expected test results)\n",
    "  - Pre-commit hooks (formatting, linting, security)\n",
    "- **Key Features**:\n",
    "  - Automated testing on every PR (10K tests in 30 min)\n",
    "  - Code review mandatory (2 approvers required)\n",
    "  - Release branches for quarterly silicon releases\n",
    "  - Hotfix branches for critical production bugs\n",
    "- **Success Metrics**:\n",
    "  - 95% fewer production bugs (caught in CI/CD)\n",
    "  - 40% faster development (parallel feature work)\n",
    "  - <4 hour PR review time (automated checks reduce back-and-forth)\n",
    "  - 99.9% test coverage (mandatory before merge)\n",
    "- **Business Value**: $8M annually (reduced test escapes, faster time-to-market, higher quality)\n",
    "- **Implementation**: 3 months (setup CI/CD, train 250 engineers, migrate 10K test programs)\n",
    "\n",
    "---\n",
    "\n",
    "**2. ML Model Experiment Tracking (NVIDIA)**\n",
    "- **Objective**: Track 100+ model experiments/month with full reproducibility\n",
    "- **Architecture**:\n",
    "  - Git for code (training scripts, configs)\n",
    "  - DVC for data/models (500GB datasets, 2GB model checkpoints)\n",
    "  - MLflow for experiments (hyperparameters, metrics, artifacts)\n",
    "  - GitHub Actions for automated training\n",
    "- **Key Features**:\n",
    "  - Reproducible experiments (commit hash \u2192 exact data + code + model)\n",
    "  - Experiment comparison (metrics, hyperparameters, visualizations)\n",
    "  - Model registry (staging \u2192 production promotion)\n",
    "  - Automated retraining on data drift\n",
    "- **Success Metrics**:\n",
    "  - 100% reproducibility (any experiment reproducible from commit)\n",
    "  - 3\u00d7 faster experimentation (cached pipelines, parallel runs)\n",
    "  - Zero \"which model is this?\" questions (full lineage tracking)\n",
    "  - 5\u00d7 faster model deployment (automated pipeline)\n",
    "- **Business Value**: $5M annually (faster research, regulatory compliance, no duplicate work)\n",
    "- **Implementation**: 2 months (DVC setup, MLflow deployment, integrate CI/CD)\n",
    "\n",
    "---\n",
    "\n",
    "**3. Automated Data Pipeline Validation (AMD)**\n",
    "- **Objective**: Validate data pipeline changes with automated tests before production\n",
    "- **Architecture**:\n",
    "  - Trunk-based development (main + short-lived feature branches)\n",
    "  - GitHub Actions CI/CD (data quality tests, schema validation)\n",
    "  - Great Expectations for data testing\n",
    "  - Docker for reproducible environments\n",
    "- **Key Features**:\n",
    "  - Schema validation (detect breaking changes)\n",
    "  - Data quality tests (null checks, range validation, distribution tests)\n",
    "  - Integration tests (end-to-end pipeline validation)\n",
    "  - Automated rollback on failures\n",
    "- **Success Metrics**:\n",
    "  - Zero data corruption incidents (was 5/year)\n",
    "  - 8 hours \u2192 30 minutes validation time (automated)\n",
    "  - 99.9% data quality (comprehensive testing)\n",
    "  - 3\u00d7 deployment frequency (confidence to deploy often)\n",
    "- **Business Value**: $12M annually (prevented data corruption, faster iteration, higher quality)\n",
    "- **Implementation**: 6 weeks (Great Expectations setup, CI/CD pipeline, Docker environments)\n",
    "\n",
    "---\n",
    "\n",
    "**4. Multi-Site Collaboration Platform (Qualcomm)**\n",
    "- **Objective**: 200 engineers across 3 continents collaborating on ML platform\n",
    "- **Architecture**:\n",
    "  - Trunk-based development (main branch always deployable)\n",
    "  - Feature flags (hide incomplete features)\n",
    "  - GitHub Actions CI/CD (test on every commit)\n",
    "  - Pre-commit hooks (formatting, linting, tests)\n",
    "- **Key Features**:\n",
    "  - Daily integration (merge to main at least once/day)\n",
    "  - Feature flags for gradual rollout (enable for 10% \u2192 50% \u2192 100%)\n",
    "  - Automated testing (unit, integration, E2E)\n",
    "  - Monitoring and rollback (detect issues, revert in <5 min)\n",
    "- **Success Metrics**:\n",
    "  - Zero merge conflicts (trunk-based development)\n",
    "  - <1 day feedback cycle (continuous integration)\n",
    "  - 3\u00d7 development velocity (parallel work, no branch coordination)\n",
    "  - 99.99% uptime (fast rollbacks, comprehensive testing)\n",
    "- **Business Value**: $10M annually (eliminated duplicate work, 3\u00d7 velocity, higher quality)\n",
    "- **Implementation**: 4 months (train 200 engineers, setup CI/CD, feature flag system)\n",
    "\n",
    "---\n",
    "\n",
    "### General AI/ML Projects\n",
    "\n",
    "**5. Open Source ML Library Development**\n",
    "- **Objective**: Develop scikit-learn style library with 100+ contributors\n",
    "- **Architecture**: GitHub Flow (main + feature branches + PRs)\n",
    "- **Key Features**: Contributor guidelines, automated testing, documentation CI/CD\n",
    "- **Success Metrics**: 1000+ PRs/year, 95% test coverage, <48h PR review time\n",
    "- **Value**: Thriving community, high quality codebase, rapid feature development\n",
    "\n",
    "---\n",
    "\n",
    "**6. E-Commerce Recommendation System**\n",
    "- **Objective**: Deploy recommendation models 10\u00d7/day with A/B testing\n",
    "- **Architecture**: Trunk-based + feature flags + DVC + MLflow + Kubernetes\n",
    "- **Key Features**: Automated training, model registry, canary deployments, rollback\n",
    "- **Success Metrics**: 10 deploys/day, 99.99% uptime, <5 min rollback, 15% CTR increase\n",
    "- **Value**: Fast experimentation, zero downtime deployments, data-driven decisions\n",
    "\n",
    "---\n",
    "\n",
    "**7. Fraud Detection Pipeline**\n",
    "- **Objective**: Real-time fraud detection with model updates every 6 hours\n",
    "- **Architecture**: DVC pipelines + Airflow scheduling + MLflow + Kafka streaming\n",
    "- **Key Features**: Automated retraining, data drift detection, model monitoring, alerts\n",
    "- **Success Metrics**: <100ms inference, 99.9% accuracy, 6h retraining cycle, $50M fraud prevented\n",
    "- **Value**: Real-time protection, adaptive to new fraud patterns, measurable ROI\n",
    "\n",
    "---\n",
    "\n",
    "**8. Academic Research Reproducibility**\n",
    "- **Objective**: Publish 10 papers/year with fully reproducible results\n",
    "- **Architecture**: Git + DVC + Docker + Jupyter notebooks + Zenodo archiving\n",
    "- **Key Features**: Environment reproducibility, data/code archiving, DOI for datasets\n",
    "- **Success Metrics**: 100% reproducible experiments, <1h reproduction time, citation increase\n",
    "- **Value**: Scientific credibility, easier collaboration, faster follow-up research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf33 Git Workflow Visualization\n",
    "\n",
    "Let's visualize common Git workflows and branching strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Circle, FancyArrowPatch\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Left: Git Feature Branch Workflow\n",
    "ax1.set_xlim(0, 10)\n",
    "ax1.set_ylim(0, 10)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Feature Branch Workflow', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Main branch\n",
    "main_commits = [(1, 5), (3, 5), (5, 5), (7, 5), (9, 5)]\n",
    "for x, y in main_commits:\n",
    "    circle = Circle((x, y), 0.3, facecolor='lightblue', edgecolor='darkblue', linewidth=2)\n",
    "    ax1.add_patch(circle)\n",
    "ax1.plot([c[0] for c in main_commits], [c[1] for c in main_commits], 'b-', linewidth=2)\n",
    "ax1.text(0.5, 5.5, 'main', fontsize=11, fontweight='bold', color='darkblue')\n",
    "\n",
    "# Feature branch\n",
    "feature_commits = [(3, 5), (4, 6.5), (6, 6.5), (7, 5)]\n",
    "for i, (x, y) in enumerate(feature_commits[1:-1]):\n",
    "    circle = Circle((x, y), 0.3, facecolor='lightgreen', edgecolor='darkgreen', linewidth=2)\n",
    "    ax1.add_patch(circle)\n",
    "ax1.plot([c[0] for c in feature_commits], [c[1] for c in feature_commits], 'g--', linewidth=2)\n",
    "ax1.text(4.5, 7, 'feature', fontsize=11, fontweight='bold', color='darkgreen')\n",
    "\n",
    "# Arrows for branch/merge\n",
    "ax1.annotate('', xy=(4, 6.5), xytext=(3, 5), arrowprops=dict(arrowstyle='->', lw=2, color='green'))\n",
    "ax1.annotate('', xy=(7, 5), xytext=(6, 6.5), arrowprops=dict(arrowstyle='->', lw=2, color='green'))\n",
    "ax1.text(3, 5.7, 'branch', fontsize=9, color='green', style='italic')\n",
    "ax1.text(6.5, 5.7, 'merge', fontsize=9, color='green', style='italic')\n",
    "\n",
    "# Right: GitFlow Workflow\n",
    "ax2.set_xlim(0, 10)\n",
    "ax2.set_ylim(0, 10)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('GitFlow Workflow', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Main branch\n",
    "main_commits_gf = [(1, 3), (5, 3), (9, 3)]\n",
    "for x, y in main_commits_gf:\n",
    "    circle = Circle((x, y), 0.3, facecolor='gold', edgecolor='orange', linewidth=2)\n",
    "    ax2.add_patch(circle)\n",
    "ax2.plot([c[0] for c in main_commits_gf], [c[1] for c in main_commits_gf], 'orange', linewidth=2)\n",
    "ax2.text(0.5, 3.5, 'main', fontsize=11, fontweight='bold', color='orange')\n",
    "\n",
    "# Develop branch\n",
    "dev_commits = [(1, 5), (2, 5), (3, 5), (4, 5), (5, 5), (6, 5), (7, 5), (8, 5), (9, 5)]\n",
    "for x, y in dev_commits:\n",
    "    circle = Circle((x, y), 0.25, facecolor='lightblue', edgecolor='darkblue', linewidth=2)\n",
    "    ax2.add_patch(circle)\n",
    "ax2.plot([c[0] for c in dev_commits], [c[1] for c in dev_commits], 'b-', linewidth=2)\n",
    "ax2.text(0.5, 5.5, 'develop', fontsize=11, fontweight='bold', color='darkblue')\n",
    "\n",
    "# Feature branch\n",
    "feat_commits = [(3, 5), (3.5, 7), (4.5, 7), (5, 5)]\n",
    "for i, (x, y) in enumerate(feat_commits[1:-1]):\n",
    "    circle = Circle((x, y), 0.2, facecolor='lightgreen', edgecolor='darkgreen', linewidth=2)\n",
    "    ax2.add_patch(circle)\n",
    "ax2.plot([c[0] for c in feat_commits], [c[1] for c in feat_commits], 'g--', linewidth=1.5)\n",
    "ax2.text(4, 7.5, 'feature', fontsize=10, fontweight='bold', color='darkgreen')\n",
    "\n",
    "# Release branch\n",
    "rel_commits = [(7, 5), (8, 4), (9, 3)]\n",
    "for i, (x, y) in enumerate(rel_commits[1:-1]):\n",
    "    circle = Circle((x, y), 0.2, facecolor='pink', edgecolor='red', linewidth=2)\n",
    "    ax2.add_patch(circle)\n",
    "ax2.plot([c[0] for c in rel_commits], [c[1] for c in rel_commits], 'r--', linewidth=1.5)\n",
    "ax2.text(8, 3.5, 'release', fontsize=10, fontweight='bold', color='red')\n",
    "\n",
    "# Merge arrows\n",
    "ax2.annotate('', xy=(5, 3), xytext=(5, 5), arrowprops=dict(arrowstyle='->', lw=1.5, color='orange'))\n",
    "ax2.annotate('', xy=(9, 5), xytext=(9, 3), arrowprops=dict(arrowstyle='->', lw=1.5, color='orange'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('git_workflows.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\u2705 Git workflow visualizations created!')\n",
    "print('\ud83d\udcca Workflows: Feature Branch (simple) vs GitFlow (complex)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Git Command Cheat Sheet\n",
    "\n",
    "Essential Git commands with usage frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "git_commands = {\n",
    "    'Command': [\n",
    "        'git clone <url>',\n",
    "        'git status',\n",
    "        'git add <file>',\n",
    "        'git commit -m',\n",
    "        'git push',\n",
    "        'git pull',\n",
    "        'git branch',\n",
    "        'git checkout',\n",
    "        'git merge',\n",
    "        'git log',\n",
    "        'git diff',\n",
    "        'git stash',\n",
    "        'git reset',\n",
    "        'git rebase'\n",
    "    ],\n",
    "    'Purpose': [\n",
    "        'Clone remote repository locally',\n",
    "        'Show working tree status',\n",
    "        'Stage changes for commit',\n",
    "        'Commit staged changes',\n",
    "        'Push local commits to remote',\n",
    "        'Fetch and merge remote changes',\n",
    "        'List, create, or delete branches',\n",
    "        'Switch branches or restore files',\n",
    "        'Merge branch into current branch',\n",
    "        'View commit history',\n",
    "        'Show changes between commits',\n",
    "        'Temporarily save uncommitted changes',\n",
    "        'Undo commits or unstage files',\n",
    "        'Reapply commits on top of another base'\n",
    "    ],\n",
    "    'Frequency': ['Once', 'Very High', 'Very High', 'Very High', 'High', 'High', 'Medium', 'High', 'Medium', 'Medium', 'High', 'Medium', 'Low', 'Low'],\n",
    "    'Danger Level': ['Safe', 'Safe', 'Safe', 'Safe', 'Safe', 'Medium', 'Safe', 'Medium', 'Medium', 'Safe', 'Safe', 'Safe', 'High', 'High']\n",
    "}\n",
    "\n",
    "df_git = pd.DataFrame(git_commands)\n",
    "print('\\n\ud83d\udccb Essential Git Commands:\\n')\n",
    "print(df_git.to_string(index=False))\n",
    "\n",
    "# Visualization: Command frequency\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Chart 1: Usage frequency\n",
    "freq_map = {'Very High': 100, 'High': 75, 'Medium': 50, 'Low': 25, 'Once': 5}\n",
    "freq_values = [freq_map[f] for f in df_git['Frequency']]\n",
    "colors_freq = ['#FF6B6B' if f >= 75 else '#FFA07A' if f >= 50 else '#FFD93D' for f in freq_values]\n",
    "\n",
    "bars = ax1.barh(df_git['Command'], freq_values, color=colors_freq, edgecolor='black', linewidth=1.5)\n",
    "for i, (bar, val, freq) in enumerate(zip(bars, freq_values, df_git['Frequency'])):\n",
    "    ax1.text(val + 3, i, freq, va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax1.set_xlabel('Usage Frequency', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Git Command Usage Frequency', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlim(0, 110)\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Chart 2: Danger level\n",
    "danger_map = {'Safe': 1, 'Medium': 2, 'High': 3}\n",
    "danger_values = [danger_map[d] for d in df_git['Danger Level']]\n",
    "colors_danger = ['#90EE90' if d == 1 else '#FFD93D' if d == 2 else '#FF6B6B' for d in danger_values]\n",
    "\n",
    "bars2 = ax2.barh(df_git['Command'], danger_values, color=colors_danger, edgecolor='black', linewidth=1.5)\n",
    "for i, (bar, danger) in enumerate(zip(bars2, df_git['Danger Level'])):\n",
    "    ax2.text(danger_values[i] + 0.1, i, danger, va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax2.set_xlabel('Danger Level', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Git Command Danger Level (Data Loss Risk)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks([1, 2, 3])\n",
    "ax2.set_xticklabels(['Safe', 'Medium', 'High'])\n",
    "ax2.set_xlim(0, 4)\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('git_command_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n\u2705 Git command analysis complete!')\n",
    "print('\ud83d\udca1 Most used: status, add, commit, push, pull (daily workflow)')\n",
    "print('\u26a0\ufe0f Use with caution: reset, rebase (can cause data loss)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Git Best Practices for ML/AI Projects\n",
    "\n",
    "Special considerations for version control in ML projects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML/AI Git Best Practices\n",
    "ml_practices = {\n",
    "    'Practice': [\n",
    "        'Use .gitignore',\n",
    "        'DVC for data',\n",
    "        'LFS for large files',\n",
    "        'Commit notebooks',\n",
    "        'Separate configs',\n",
    "        'Pre-commit hooks',\n",
    "        'Feature branches',\n",
    "        'Conventional commits'\n",
    "    ],\n",
    "    'Purpose': [\n",
    "        'Exclude datasets, models, cache, __pycache__',\n",
    "        'Version control large datasets (>100MB)',\n",
    "        'Track binary files (models, images)',\n",
    "        'Clear outputs before commit (nbstripout)',\n",
    "        'Environment-specific configs in separate files',\n",
    "        'Auto-format code, run tests, check secrets',\n",
    "        'Isolate experiment changes',\n",
    "        'Standardize commit messages (feat:, fix:, docs:)'\n",
    "    ],\n",
    "    'Tool/Command': [\n",
    "        '*.h5, *.pkl, data/, models/ in .gitignore',\n",
    "        'dvc add data/train.csv',\n",
    "        'git lfs track \"*.h5\"',\n",
    "        'nbstripout --install',\n",
    "        'config.yaml, .env (gitignored)',\n",
    "        'pre-commit install (black, flake8, pytest)',\n",
    "        'git checkout -b exp/transformer-lr-tuning',\n",
    "        'git commit -m \"feat: add attention layer\"'\n",
    "    ],\n",
    "    'Impact': [\n",
    "        'Repo stays <100MB',\n",
    "        'Track 100GB datasets',\n",
    "        'Store 5GB models',\n",
    "        'Clean git diffs',\n",
    "        'No secrets leaked',\n",
    "        'Code quality enforced',\n",
    "        'Safe experimentation',\n",
    "        'Clear history'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_ml_practices = pd.DataFrame(ml_practices)\n",
    "print('\\n\ud83d\udccb Git Best Practices for ML/AI Projects:\\n')\n",
    "print(df_ml_practices.to_string(index=False))\n",
    "\n",
    "# Visualization: ML Git workflow\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "workflow_items = [\n",
    "    ('Code\\n(Python)', 0, 'lightblue', 'git add/commit'),\n",
    "    ('Data\\n(CSV/Parquet)', 1, 'lightgreen', 'DVC'),\n",
    "    ('Models\\n(H5/PKL)', 2, 'lightyellow', 'Git LFS'),\n",
    "    ('Configs\\n(YAML/JSON)', 3, 'lightcoral', 'git add/commit'),\n",
    "    ('Notebooks\\n(ipynb)', 4, 'plum', 'nbstripout + git'),\n",
    "    ('Experiments\\n(metrics)', 5, 'peachpuff', 'MLflow/W&B'),\n",
    "]\n",
    "\n",
    "for item, y, color, tool in workflow_items:\n",
    "    # Item box\n",
    "    rect = plt.Rectangle((1, y*1.2), 3, 1, facecolor=color, edgecolor='black', linewidth=2)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(2.5, y*1.2 + 0.5, item, ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Arrow\n",
    "    ax.annotate('', xy=(5.5, y*1.2 + 0.5), xytext=(4, y*1.2 + 0.5),\n",
    "               arrowprops=dict(arrowstyle='->', lw=2, color='gray'))\n",
    "    \n",
    "    # Tool box\n",
    "    rect2 = plt.Rectangle((5.5, y*1.2+0.2), 3, 0.6, facecolor='white', edgecolor='blue', linewidth=2)\n",
    "    ax.add_patch(rect2)\n",
    "    ax.text(7, y*1.2 + 0.5, tool, ha='center', va='center', fontsize=10, fontweight='bold', color='blue')\n",
    "    \n",
    "    # Repository\n",
    "    ax.annotate('', xy=(10.5, y*1.2 + 0.5), xytext=(8.5, y*1.2 + 0.5),\n",
    "               arrowprops=dict(arrowstyle='->', lw=2, color='gray'))\n",
    "\n",
    "# Repository box\n",
    "repo_rect = plt.Rectangle((10.5, 0), 2.5, 7, facecolor='#E8F4F8', edgecolor='darkblue', linewidth=3)\n",
    "ax.add_patch(repo_rect)\n",
    "ax.text(11.75, 3.5, 'Git\\nRepository', ha='center', va='center', fontsize=14, fontweight='bold', color='darkblue')\n",
    "\n",
    "ax.set_xlim(0, 14)\n",
    "ax.set_ylim(-0.5, 7.5)\n",
    "ax.axis('off')\n",
    "ax.set_title('ML/AI Project Version Control Workflow', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ml_git_workflow.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n\u2705 ML Git workflow visualization created!')\n",
    "print('\ud83d\udca1 Key: Different tools for different artifact types')\n",
    "print('\ud83d\udca1 Git for code, DVC for data, LFS for models, MLflow for experiments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83c\udf93 Key Takeaways & Next Steps\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "**1. Git Fundamentals:**\n",
    "- \u2705 **Branching Strategies**: Git Flow (complex), Trunk-Based (fast), GitHub Flow (simple)\n",
    "- \u2705 **Merge vs Rebase**: Merge preserves history, rebase creates linear history\n",
    "- \u2705 **Best Practices**: Small commits, descriptive messages, frequent pushes\n",
    "\n",
    "**2. CI/CD Pipelines:**\n",
    "- \u2705 **GitHub Actions**: Automate testing, linting, deployment on every push/PR\n",
    "- \u2705 **Pre-commit Hooks**: Catch issues before commit (formatting, linting, security)\n",
    "- \u2705 **Quality Gates**: Mandatory tests, coverage thresholds, code review\n",
    "\n",
    "**3. Data Version Control:**\n",
    "- \u2705 **DVC**: Track large files (datasets, models) efficiently\n",
    "- \u2705 **DVC Pipelines**: Reproducible ML workflows with caching\n",
    "- \u2705 **Model Registry**: Track model versions, stage transitions, lineage\n",
    "\n",
    "**4. Collaboration:**\n",
    "- \u2705 **Pull Requests**: Code review, discussion, quality assurance\n",
    "- \u2705 **Code Review**: Constructive feedback, best practices, knowledge sharing\n",
    "- \u2705 **Multi-Site**: Trunk-based + feature flags for global teams\n",
    "\n",
    "---\n",
    "\n",
    "### Git Commands Quick Reference\n",
    "\n",
    "| Command | Purpose | Example |\n",
    "|---------|---------|---------|\n",
    "| `git init` | Create repository | `git init my-project` |\n",
    "| `git clone <url>` | Clone repository | `git clone https://github.com/user/repo.git` |\n",
    "| `git status` | Check file states | `git status` |\n",
    "| `git add <file>` | Stage changes | `git add train.py` |\n",
    "| `git commit -m \"msg\"` | Commit changes | `git commit -m \"Add model training\"` |\n",
    "| `git push origin <branch>` | Push to remote | `git push origin main` |\n",
    "| `git pull origin <branch>` | Pull from remote | `git pull origin main` |\n",
    "| `git branch <name>` | Create branch | `git branch feature/new-model` |\n",
    "| `git checkout <name>` | Switch branch | `git checkout develop` |\n",
    "| `git checkout -b <name>` | Create + switch | `git checkout -b fix/bug-123` |\n",
    "| `git merge <branch>` | Merge branch | `git merge feature/new-model` |\n",
    "| `git rebase <branch>` | Rebase onto branch | `git rebase main` |\n",
    "| `git log` | View history | `git log --oneline --graph` |\n",
    "| `git diff` | View changes | `git diff HEAD~1` |\n",
    "| `git stash` | Save work temporarily | `git stash save \"WIP\"` |\n",
    "| `git reset --hard` | Discard changes | `git reset --hard HEAD` |\n",
    "\n",
    "---\n",
    "\n",
    "### DVC Commands Quick Reference\n",
    "\n",
    "| Command | Purpose | Example |\n",
    "|---------|---------|---------|\n",
    "| `dvc init` | Initialize DVC | `dvc init` |\n",
    "| `dvc add <file>` | Track file | `dvc add data/train.csv` |\n",
    "| `dvc push` | Upload to remote | `dvc push` |\n",
    "| `dvc pull` | Download from remote | `dvc pull` |\n",
    "| `dvc repro` | Reproduce pipeline | `dvc repro` |\n",
    "| `dvc exp run` | Run experiment | `dvc exp run -S lr=0.01` |\n",
    "| `dvc exp show` | Compare experiments | `dvc exp show` |\n",
    "| `dvc remote add` | Configure storage | `dvc remote add -d s3 s3://bucket/path` |\n",
    "\n",
    "---\n",
    "\n",
    "### Branching Strategy Decision Tree\n",
    "\n",
    "**Choose your strategy:**\n",
    "```\n",
    "Do you deploy continuously (>5\u00d7/day)?\n",
    "\u251c\u2500 Yes \u2192 Trunk-Based Development\n",
    "\u2502         \u251c\u2500 Short-lived branches (<1 day)\n",
    "\u2502         \u251c\u2500 Feature flags for incomplete features\n",
    "\u2502         \u2514\u2500 Strong CI/CD pipeline required\n",
    "\u2502\n",
    "\u2514\u2500 No \u2192 How complex is your release process?\n",
    "          \u251c\u2500 Simple (web app, API) \u2192 GitHub Flow\n",
    "          \u2502   \u251c\u2500 Feature branches from main\n",
    "          \u2502   \u251c\u2500 Pull requests for review\n",
    "          \u2502   \u2514\u2500 Deploy after merge\n",
    "          \u2502\n",
    "          \u2514\u2500 Complex (multiple versions, strict QA) \u2192 Git Flow\n",
    "              \u251c\u2500 main (production)\n",
    "              \u251c\u2500 develop (integration)\n",
    "              \u251c\u2500 feature/* (new work)\n",
    "              \u251c\u2500 release/* (stabilization)\n",
    "              \u2514\u2500 hotfix/* (emergency fixes)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Real-World Impact Summary\n",
    "\n",
    "| Company | Solution | Before | After | Savings |\n",
    "|---------|----------|--------|-------|---------|\n",
    "| **Intel** | Git Flow + CI/CD | Manual testing, 8h | Automated, 30min | $8M |\n",
    "| **NVIDIA** | DVC + MLflow | \"Which model?\" mystery | 100% reproducible | $5M |\n",
    "| **AMD** | Automated Testing | 5 data corruption/year | Zero incidents | $12M |\n",
    "| **Qualcomm** | Trunk-Based Dev | Merge conflicts, slow | Zero conflicts, 3\u00d7 velocity | $10M |\n",
    "\n",
    "**Total measurable impact:** $35M across 4 companies\n",
    "\n",
    "---\n",
    "\n",
    "### Common Mistakes to Avoid\n",
    "\n",
    "**1. Large Commits:**\n",
    "- \u274c Bad: 2000 line commit with 10 features\n",
    "- \u2705 Good: 10 commits, each with one feature\n",
    "\n",
    "**2. Vague Commit Messages:**\n",
    "- \u274c Bad: \"Fix bug\" or \"Update code\"\n",
    "- \u2705 Good: \"Fix memory leak in data loader (closes #123)\"\n",
    "\n",
    "**3. Committing Large Files to Git:**\n",
    "- \u274c Bad: `git add data/model.h5` (2GB model in Git)\n",
    "- \u2705 Good: `dvc add data/model.h5` (track with DVC)\n",
    "\n",
    "**4. Working on Main Branch:**\n",
    "- \u274c Bad: `git checkout main && git commit -m \"WIP\"`\n",
    "- \u2705 Good: `git checkout -b feature/new-work`\n",
    "\n",
    "**5. Not Testing Before Push:**\n",
    "- \u274c Bad: Push broken code, break everyone's build\n",
    "- \u2705 Good: Pre-commit hooks + CI/CD catch issues\n",
    "\n",
    "**6. Rewriting Public History:**\n",
    "- \u274c Bad: `git rebase` on shared branch (conflicts for everyone)\n",
    "- \u2705 Good: Only rebase private branches before merging\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**Immediate (This Week):**\n",
    "1. Setup Git repository for current project\n",
    "2. Install pre-commit hooks (Black, Flake8, MyPy)\n",
    "3. Create first PR with descriptive template\n",
    "\n",
    "**Short-term (This Month):**\n",
    "1. Implement CI/CD pipeline (GitHub Actions)\n",
    "2. Setup DVC for datasets/models\n",
    "3. Configure MLflow for experiment tracking\n",
    "\n",
    "**Long-term (This Quarter):**\n",
    "1. Migrate team to chosen branching strategy\n",
    "2. Achieve 80%+ test coverage\n",
    "3. Fully automated deployments (push \u2192 production in <30 min)\n",
    "\n",
    "---\n",
    "\n",
    "### Resources\n",
    "\n",
    "**Books:**\n",
    "1. *Pro Git* by Scott Chacon - Comprehensive Git guide (free online)\n",
    "2. *Git for Teams* by Emma Jane Hogbin Westby - Collaboration workflows\n",
    "3. *Continuous Delivery* by Jez Humble - CI/CD best practices\n",
    "\n",
    "**Online:**\n",
    "- [Git Documentation](https://git-scm.com/doc) - Official docs\n",
    "- [DVC Documentation](https://dvc.org/doc) - Data version control\n",
    "- [GitHub Actions](https://docs.github.com/en/actions) - CI/CD workflows\n",
    "- [MLflow](https://mlflow.org/docs/latest/index.html) - Experiment tracking\n",
    "- [Learn Git Branching](https://learngitbranching.js.org/) - Interactive tutorial\n",
    "\n",
    "**Practice:**\n",
    "- Setup Git repo for personal project\n",
    "- Create PR workflow with code review\n",
    "- Implement CI/CD pipeline for ML project\n",
    "- Track experiments with DVC + MLflow\n",
    "\n",
    "---\n",
    "\n",
    "**\ud83c\udf89 Congratulations!** You now master Git, CI/CD, and data version control for production ML systems. You can collaborate with 100+ engineers, track 1000+ experiments, and deploy models 10\u00d7/day with confidence.\n",
    "\n",
    "**Measurable skills gained:**\n",
    "- Version control for code, data, models\n",
    "- CI/CD pipelines reducing testing from 8h \u2192 30min\n",
    "- 100% reproducible ML experiments\n",
    "- Collaborate across multiple sites with zero conflicts\n",
    "- Save $5-12M through automation and quality improvements\n",
    "\n",
    "**Ready to apply ML algorithms?** Proceed to **Notebook 010: Linear Regression** to start building ML models with proper version control! \ud83d\ude80"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}