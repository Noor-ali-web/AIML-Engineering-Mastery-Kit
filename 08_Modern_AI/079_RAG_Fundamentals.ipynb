{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26c9cb6",
   "metadata": {},
   "source": [
    "# 079: RAG (Retrieval-Augmented Generation) Fundamentals\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- **Understand** the RAG architecture and why it's crucial for LLM applications\n",
    "- **Implement** document chunking and embedding strategies from scratch\n",
    "- **Build** semantic search systems using vector databases (FAISS)\n",
    "- **Create** production RAG pipelines with context retrieval and generation\n",
    "- **Apply** RAG to semiconductor test documentation and failure analysis\n",
    "- **Evaluate** RAG systems using retrieval and generation metrics\n",
    "\n",
    "## üìö What is RAG?\n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)** combines:\n",
    "1. **Information Retrieval** - Finding relevant documents from a knowledge base\n",
    "2. **Language Generation** - Using retrieved context to generate accurate responses\n",
    "\n",
    "**Why RAG?**\n",
    "- ‚úÖ Reduces hallucinations by grounding LLM responses in factual data\n",
    "- ‚úÖ Enables LLMs to access current/private information (not in training data)\n",
    "- ‚úÖ More cost-effective than fine-tuning for domain-specific knowledge\n",
    "- ‚úÖ Transparent - can trace answers back to source documents\n",
    "\n",
    "## üè≠ Post-Silicon Validation Use Cases\n",
    "\n",
    "**Technical Documentation Search**\n",
    "- Query: \"What are the voltage specifications for LPDDR5?\"\n",
    "- Retrieve: Relevant sections from datasheets, test specs\n",
    "- Generate: Concise answer with specific voltage ranges and conditions\n",
    "\n",
    "**Failure Analysis Assistant**\n",
    "- Query: \"Similar failures to wafer W123 die position (50, 75)?\"\n",
    "- Retrieve: Historical failure reports, wafer maps, test logs\n",
    "- Generate: Root cause analysis with similar case references\n",
    "\n",
    "**Test Parameter Recommendations**\n",
    "- Query: \"Optimal test coverage for power consumption validation?\"\n",
    "- Retrieve: Test plans, yield correlation data, best practices\n",
    "- Generate: Recommended test parameters and sequencing\n",
    "\n",
    "## üîÑ RAG Architecture Workflow\n",
    "\n",
    "```mermaid\n",
    "graph TB\n",
    "    A[Documents] --> B[Chunking]\n",
    "    B --> C[Embedding Model]\n",
    "    C --> D[Vector Database]\n",
    "    \n",
    "    E[User Query] --> F[Query Embedding]\n",
    "    F --> G[Semantic Search]\n",
    "    D --> G\n",
    "    \n",
    "    G --> H[Top-K Retrieved Docs]\n",
    "    H --> I[Context Assembly]\n",
    "    E --> I\n",
    "    \n",
    "    I --> J[LLM with Context]\n",
    "    J --> K[Generated Response]\n",
    "    \n",
    "    style A fill:#e1f5ff\n",
    "    style D fill:#fff4e1\n",
    "    style J fill:#f0e1ff\n",
    "    style K fill:#e1ffe1\n",
    "```\n",
    "\n",
    "## üìä Learning Path Context\n",
    "\n",
    "**Prerequisites:**\n",
    "- 072: GPT & Large Language Models (LLM fundamentals)\n",
    "- 078: Multimodal LLMs (embedding concepts)\n",
    "- 058: Transformers & Self-Attention (attention mechanism)\n",
    "\n",
    "**Next Steps:**\n",
    "- 080: Advanced RAG Techniques (hybrid search, re-ranking)\n",
    "- 083: AI Agents (RAG as agent tool)\n",
    "- 085: Vector Databases (scaling RAG systems)\n",
    "\n",
    "---\n",
    "\n",
    "Let's build comprehensive RAG systems from the ground up! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350981fc",
   "metadata": {},
   "source": [
    "## **Why Retrieval-Augmented Generation?**\n",
    "\n",
    "### **The LLM Knowledge Problem**\n",
    "\n",
    "**Before RAG:**\n",
    "- ‚ùå LLMs only know information from training data (static, outdated)\n",
    "- ‚ùå Cannot access private/proprietary documents\n",
    "- ‚ùå Hallucinate when uncertain (generate plausible but incorrect information)\n",
    "- ‚ùå Cannot cite sources (no transparency)\n",
    "\n",
    "**After RAG:**\n",
    "- ‚úÖ Access current and private information dynamically\n",
    "- ‚úÖ Ground responses in retrieved factual documents\n",
    "- ‚úÖ Cite sources for transparency and verification\n",
    "- ‚úÖ More cost-effective than fine-tuning for knowledge updates\n",
    "\n",
    "### **The Hallucination Crisis**\n",
    "\n",
    "**Example hallucination scenarios:**\n",
    "- **General LLM:** \"Tell me about the XYZ-3000 chip specifications\" ‚Üí Generates plausible but entirely fictional specifications\n",
    "- **RAG System:** Retrieves actual XYZ-3000 datasheet ‚Üí Cites exact voltage ranges, frequencies from real document\n",
    "\n",
    "**Research shows:** RAG reduces hallucinations by **60-80%** in knowledge-intensive tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### **Semiconductor Test Documentation Challenges**\n",
    "\n",
    "**The documentation problem:**\n",
    "- üìö **Thousands of documents:** Test specs, datasheets, failure reports, design docs\n",
    "- üîç **Hard to search:** Technical jargon, buried in PDFs, inconsistent terminology  \n",
    "- ‚è∞ **Time-critical:** Engineers need answers during debug sessions (not hours later)\n",
    "- üîê **Confidential:** Cannot use public LLMs with proprietary data\n",
    "\n",
    "**RAG solution value:**\n",
    "- ‚ö° **Instant answers:** Query \"LPDDR5 timing specs\" ‚Üí retrieve relevant sections ‚Üí generate concise answer\n",
    "- üí∞ **Cost savings:** Reduce engineer search time from 30min to 30sec (40√ó faster)\n",
    "- üéØ **Accuracy:** Ground responses in actual test documents (eliminate guesswork)\n",
    "- üîí **Security:** Deploy RAG system on-premises with internal docs\n",
    "\n",
    "**ROI calculation:**\n",
    "- 100 engineers √ó 2 hours/week searching docs = 200 engineer-hours/week\n",
    "- RAG reduces search time by 80% = 160 hours saved/week\n",
    "- At $100/hour loaded cost = **$16K/week savings = $832K/year**\n",
    "\n",
    "---\n",
    "\n",
    "## **What We'll Build**\n",
    "\n",
    "### **1. Educational: RAG from Scratch (NumPy + Simple Embeddings)**\n",
    "\n",
    "Implement core RAG components to understand the mechanics:\n",
    "- Document chunking (fixed-size, sentence-based, semantic)\n",
    "- Simple embedding model (TF-IDF ‚Üí dense vectors)\n",
    "- Cosine similarity search\n",
    "- Context assembly for LLM prompt\n",
    "\n",
    "### **2. Production: Semantic Search with Sentence-BERT + FAISS**\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Documents ‚Üí Chunking (512 tokens) \n",
    "         ‚Üí Sentence-BERT embeddings (384-dim)\n",
    "         ‚Üí FAISS index (IVF + PQ for scale)\n",
    "         ‚Üí Top-K retrieval (K=3-5)\n",
    "         ‚Üí LLM with context\n",
    "```\n",
    "\n",
    "**Performance targets:**\n",
    "- Index 100K document chunks in <5 minutes\n",
    "- Query latency <100ms for top-5 retrieval\n",
    "- Retrieval accuracy (R@5) ‚â•90%\n",
    "\n",
    "### **3. Post-Silicon Validation: Test Spec RAG System**\n",
    "\n",
    "**Dataset:** 500+ semiconductor test specification documents (PDFs, 50K chunks).\n",
    "\n",
    "**Queries:**\n",
    "- \"What is the voltage range for LPDDR5 DQ pins?\"\n",
    "- \"Maximum current specification for power rail VDD_CORE?\"\n",
    "- \"Required temperature range for automotive qualification?\"\n",
    "\n",
    "**Evaluation metrics:**\n",
    "- **Retrieval:** Precision@K, Recall@K, MRR (Mean Reciprocal Rank)\n",
    "- **Generation:** ROUGE-L, BERTScore, human evaluation\n",
    "\n",
    "---\n",
    "\n",
    "## **Notebook Roadmap**\n",
    "\n",
    "### **Part 1: Mathematical Foundations** (Cell 2)\n",
    "- Embedding mathematics\n",
    "- Similarity metrics (cosine, dot product, L2)\n",
    "- Vector space retrieval theory\n",
    "\n",
    "### **Part 2: Document Chunking Strategies** (Cells 3-5)\n",
    "- Fixed-size chunking\n",
    "- Sentence-aware chunking\n",
    "- Semantic chunking\n",
    "- Overlap strategies\n",
    "\n",
    "### **Part 3: Embeddings from Scratch** (Cells 6-8)\n",
    "- TF-IDF vectorization\n",
    "- Dense embedding projection\n",
    "- Simple semantic search\n",
    "\n",
    "### **Part 4: Production Embeddings** (Cells 9-11)\n",
    "- Sentence-BERT (all-MiniLM-L6-v2)\n",
    "- OpenAI embeddings (text-embedding-3-small)\n",
    "- Embedding comparison\n",
    "\n",
    "### **Part 5: Vector Search with FAISS** (Cells 12-15)\n",
    "- FAISS index types (Flat, IVF, HNSW)\n",
    "- Building vector database\n",
    "- Efficient similarity search\n",
    "- Scaling to millions of vectors\n",
    "\n",
    "### **Part 6: Complete RAG Pipeline** (Cells 16-20)\n",
    "- End-to-end RAG system\n",
    "- Query processing\n",
    "- Context assembly\n",
    "- LLM integration (OpenAI/local)\n",
    "- Response generation\n",
    "\n",
    "### **Part 7: Post-Silicon Use Cases** (Cells 21-24)\n",
    "- Test specification search\n",
    "- Failure report retrieval\n",
    "- Design document Q&A\n",
    "- Parameter recommendation\n",
    "\n",
    "### **Part 8: Evaluation & Metrics** (Cells 25-27)\n",
    "- Retrieval metrics (Precision@K, Recall@K, MRR, NDCG)\n",
    "- Generation metrics (ROUGE, BLEU, BERTScore)\n",
    "- End-to-end evaluation\n",
    "\n",
    "### **Part 9: Real-World Projects** (Cell 28)\n",
    "- 8 production-ready RAG project ideas\n",
    "\n",
    "### **Part 10: Best Practices & Takeaways** (Cell 29)\n",
    "- When to use RAG vs fine-tuning\n",
    "- Chunking strategies guide\n",
    "- Embedding model selection\n",
    "- Production deployment patterns\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Concepts**\n",
    "\n",
    "| Concept | Definition | Why It Matters |\n",
    "|---------|------------|----------------|\n",
    "| **Embedding** | Dense vector representation of text | Captures semantic meaning for similarity search |\n",
    "| **Vector Database** | Specialized DB for embedding storage/search | Enables fast similarity queries (sub-100ms) |\n",
    "| **Chunking** | Splitting documents into smaller pieces | Balances context vs precision in retrieval |\n",
    "| **Semantic Search** | Finding similar meaning (not keywords) | Retrieves \"battery life\" when searching \"power consumption\" |\n",
    "| **Top-K Retrieval** | Return K most similar documents | Provides context without overwhelming LLM |\n",
    "| **Cosine Similarity** | Measure of vector angle (0=orthogonal, 1=identical) | Standard metric for semantic similarity |\n",
    "| **Context Window** | Max tokens LLM can process | Limits retrieved context (4K-128K tokens) |\n",
    "| **Hallucination** | LLM generating false information | RAG reduces by grounding in real documents |\n",
    "\n",
    "---\n",
    "\n",
    "## **Prerequisites**\n",
    "\n",
    "**Required notebooks:**\n",
    "- **072: GPT & Large Language Models** - Understanding LLM capabilities and limitations\n",
    "- **078: Multimodal LLMs** - Embedding concepts and representation learning\n",
    "\n",
    "**Helpful but optional:**\n",
    "- **058: Transformers & Self-Attention** - Architecture behind embedding models\n",
    "- **071: Transformers & BERT** - Sentence-BERT foundation\n",
    "\n",
    "**Skills:**\n",
    "- Python programming (classes, decorators, type hints)\n",
    "- NumPy for vector operations\n",
    "- Basic understanding of cosine similarity\n",
    "\n",
    "---\n",
    "\n",
    "## **Learning Path Context**\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[072: GPT/LLMs] --> B[079: RAG Fundamentals]\n",
    "    C[078: Multimodal LLMs] --> B\n",
    "    B --> D[080: Advanced RAG]\n",
    "    B --> E[083: AI Agents]\n",
    "    B --> F[085: Vector Databases]\n",
    "    \n",
    "    D --> G[084: LangChain]\n",
    "    E --> G\n",
    "    F --> G\n",
    "    \n",
    "    style B fill:#4CAF50,color:#fff\n",
    "    style D fill:#e1f5ff\n",
    "    style E fill:#e1f5ff\n",
    "    style F fill:#e1f5ff\n",
    "```\n",
    "\n",
    "**Current Focus:** 079 - RAG Fundamentals (you are here! üéØ)\n",
    "\n",
    "**Next Steps:**\n",
    "- **080: Advanced RAG Techniques** - Hybrid search, re-ranking, query expansion\n",
    "- **083: AI Agents** - Use RAG as agent tool for complex reasoning\n",
    "- **085: Vector Databases** - Scale RAG to millions/billions of documents\n",
    "\n",
    "---\n",
    "\n",
    "Let's build production-grade RAG systems! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e40d6",
   "metadata": {},
   "source": [
    "## üìê Part 1: Mathematical Foundations\n",
    "\n",
    "### RAG Components Mathematics\n",
    "\n",
    "**1. Document Embedding**\n",
    "\n",
    "For document chunk $d_i$, embedding function $f_{embed}$:\n",
    "\n",
    "$$\\mathbf{v}_i = f_{embed}(d_i) \\in \\mathbb{R}^{d}$$\n",
    "\n",
    "Where $d$ is embedding dimension (typically 384, 768, or 1536).\n",
    "\n",
    "**2. Semantic Similarity**\n",
    "\n",
    "Cosine similarity between query $q$ and document $d_i$:\n",
    "\n",
    "$$\\text{sim}(q, d_i) = \\frac{\\mathbf{v}_q \\cdot \\mathbf{v}_i}{||\\mathbf{v}_q|| \\cdot ||\\mathbf{v}_i||} = \\frac{\\sum_{j=1}^{d} v_{q,j} \\cdot v_{i,j}}{\\sqrt{\\sum_{j=1}^{d} v_{q,j}^2} \\cdot \\sqrt{\\sum_{j=1}^{d} v_{i,j}^2}}$$\n",
    "\n",
    "**3. Top-K Retrieval**\n",
    "\n",
    "Retrieve top $k$ most similar documents:\n",
    "\n",
    "$$D_{top-k} = \\{d_i : \\text{sim}(q, d_i) \\text{ in top } k \\text{ values}\\}$$\n",
    "\n",
    "**4. Context Assembly**\n",
    "\n",
    "Concatenate retrieved documents with query:\n",
    "\n",
    "$$\\text{context} = [d_1, d_2, ..., d_k] \\oplus q$$\n",
    "\n",
    "Where $\\oplus$ denotes concatenation with special tokens.\n",
    "\n",
    "**5. Conditional Generation**\n",
    "\n",
    "LLM generates response conditioned on context:\n",
    "\n",
    "$$P(y | q, D_{top-k}) = \\prod_{t=1}^{T} P(y_t | y_{<t}, q, D_{top-k})$$\n",
    "\n",
    "### Why This Works\n",
    "\n",
    "**Information Bottleneck:** LLMs have limited context windows (4k-128k tokens). RAG efficiently uses this by retrieving only relevant information.\n",
    "\n",
    "**Factual Grounding:** Retrieved documents provide factual basis, reducing hallucinations.\n",
    "\n",
    "**Dynamic Knowledge:** Can update knowledge base without retraining the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19811bda",
   "metadata": {},
   "source": [
    "### üìù What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Import core libraries for RAG implementation\n",
    "\n",
    "**Key Libraries:**\n",
    "- **numpy**: Vector operations for embeddings and similarity calculations\n",
    "- **sentence-transformers**: Pre-trained embedding models (SBERT)\n",
    "- **faiss**: Efficient similarity search and vector database\n",
    "- **typing**: Type hints for code clarity\n",
    "\n",
    "**Why These Libraries:**\n",
    "- **Sentence-BERT**: State-of-the-art semantic text embeddings\n",
    "- **FAISS**: Facebook's vector search library (billions of vectors, millisecond latency)\n",
    "- **NumPy**: Foundation for all numerical computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ba547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For production RAG (install if needed: pip install sentence-transformers faiss-cpu)\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import faiss\n",
    "    PRODUCTION_LIBS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PRODUCTION_LIBS_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  Production libraries not installed. Install with:\")\n",
    "    print(\"   pip install sentence-transformers faiss-cpu\")\n",
    "    print(\"   (Educational from-scratch implementation will still work)\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")\n",
    "print(f\"   Production RAG libraries available: {PRODUCTION_LIBS_AVAILABLE}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
