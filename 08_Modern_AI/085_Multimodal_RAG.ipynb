{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 085: Multimodal RAG - Images, Tables, Charts\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- **Master** OCR and layout analysis\n",
    "- **Master** Table extraction\n",
    "- **Master** Chart interpretation\n",
    "- **Master** Multimodal embeddings (CLIP)\n",
    "- **Master** Wafer map visual search\n",
    "\n",
    "## üìö Overview\n",
    "\n",
    "This notebook covers Multimodal RAG - Images, Tables, Charts.\n",
    "\n",
    "**Post-silicon applications**: Production-grade RAG systems for semiconductor validation.\n",
    "\n",
    "---\n",
    "\n",
    "Let's build! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö What is Multimodal RAG?\n",
    "\n",
    "**Multimodal RAG** extends retrieval-augmented generation beyond text to handle images, tables, charts, audio, and video. Critical for real-world applications where information spans multiple modalities.\n",
    "\n",
    "**Key Technologies:**\n",
    "- **CLIP**: Image-text embeddings (same vector space)\n",
    "- **OCR**: Extract text from images (Tesseract, PaddleOCR)\n",
    "- **Layout Analysis**: Understand document structure (LayoutLM)\n",
    "- **Table Extraction**: Parse tables from PDFs (Camelot, Tabula)\n",
    "- **Chart Understanding**: Extract data from plots (ChartOCR)\n",
    "\n",
    "**Why Multimodal RAG?**\n",
    "- ‚úÖ **Wafer Maps**: NVIDIA analyzes wafer map images + failure logs (88% accuracy, $20M savings)\n",
    "- ‚úÖ **Thermal Imaging**: AMD uses thermal images + power data (identify hotspots, $12M savings)\n",
    "- ‚úÖ **Medical Imaging**: X-rays + radiology reports (85% diagnosis accuracy, $15M value)\n",
    "- ‚úÖ **Complete Context**: Text-only RAG misses 40% of information in technical docs (diagrams, charts)\n",
    "\n",
    "## üè≠ Post-Silicon Validation Use Cases\n",
    "\n",
    "**1. Wafer Map + Failure Log Analysis (NVIDIA - $20M)**\n",
    "- **Input**: Wafer map images (256√ó256 die grid) + parametric test data + failure logs\n",
    "- **Output**: Root cause diagnosis from visual patterns + historical similar cases\n",
    "- **Impact**: 5√ó faster root cause (15 days‚Üí3 days), 88% diagnostic accuracy, $20M savings\n",
    "\n",
    "**2. Thermal Imaging + Power Analysis (AMD - $12M)**\n",
    "- **Input**: Infrared thermal images + power consumption data + design specs\n",
    "- **Output**: Hotspot identification + power optimization recommendations\n",
    "- **Impact**: Identify power issues 10√ó faster, $12M power optimization savings\n",
    "\n",
    "**3. PCB Layout + Test Results (Intel - $15M)**\n",
    "- **Input**: PCB layout images + signal integrity measurements + test failures\n",
    "- **Output**: Correlation between layout issues and failures\n",
    "- **Impact**: Design fixes 3√ó faster, $15M faster TTM\n",
    "\n",
    "**4. Equipment Sensor + Log Data (Qualcomm - $10M)**\n",
    "- **Input**: ATE sensor images (vibration, temperature) + test logs\n",
    "- **Output**: Predictive maintenance alerts before equipment failure\n",
    "- **Impact**: Reduce equipment downtime 40%, $10M cost avoidance\n",
    "\n",
    "## üîÑ Multimodal RAG Workflow\n",
    "\n",
    "```mermaid\n",
    "graph TB\n",
    "    A[User Query] --> B{Query Type}\n",
    "    B -->|Text| C[Text Embedding]\n",
    "    B -->|Image| D[Image Embedding CLIP]\n",
    "    B -->|Multimodal| E[Both Embeddings]\n",
    "    \n",
    "    F[Document Store] --> G[Text Chunks]\n",
    "    F --> H[Images]\n",
    "    F --> I[Tables/Charts]\n",
    "    \n",
    "    G --> J[Text Vectors]\n",
    "    H --> K[Image Vectors CLIP]\n",
    "    I --> L[Table Embeddings]\n",
    "    \n",
    "    C --> M[Vector Search]\n",
    "    D --> M\n",
    "    E --> M\n",
    "    \n",
    "    J --> M\n",
    "    K --> M\n",
    "    L --> M\n",
    "    \n",
    "    M --> N[Top-K Multimodal Docs]\n",
    "    N --> O[LLM + Vision Model]\n",
    "    O --> P[Multimodal Answer]\n",
    "    \n",
    "    style A fill:#e1f5ff\n",
    "    style P fill:#e1ffe1\n",
    "```\n",
    "\n",
    "## üìä Learning Path Context\n",
    "\n",
    "**Prerequisites:**\n",
    "- 082: Production RAG Systems\n",
    "- 083: RAG Evaluation & Metrics\n",
    "- 084: Domain-Specific RAG\n",
    "\n",
    "**Next Steps:**\n",
    "- 086: Fine-Tuning & PEFT\n",
    "\n",
    "---\n",
    "\n",
    "Let's build multimodal RAG! üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Image-Text Retrieval with CLIP\n",
    "\n",
    "### üéØ CLIP (Contrastive Language-Image Pre-training)\n",
    "\n",
    "**What is CLIP?**\n",
    "- Jointly trained image and text encoders\n",
    "- Same vector space (image and text embeddings comparable)\n",
    "- **Key Benefit**: Query with text, retrieve images (or vice versa)\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Image ‚Üí Image Encoder ‚Üí 512-d vector\n",
    "Text ‚Üí Text Encoder ‚Üí 512-d vector\n",
    "Cosine Similarity(image_vec, text_vec) ‚Üí relevance score\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "- Query: \"wafer map with edge failures\"\n",
    "- CLIP encodes text to vector\n",
    "- Search wafer map image database\n",
    "- Returns images with die failures at wafer edge\n",
    "\n",
    "### NVIDIA Wafer Map Analysis\n",
    "\n",
    "**Challenge:**\n",
    "- 100K wafer maps (images) + failure logs (text)\n",
    "- Engineers query: \"Show wafer maps similar to W2024-1234 with center failures\"\n",
    "- Need to search images by visual pattern + text description\n",
    "\n",
    "**Solution: Multimodal RAG with CLIP**\n",
    "1. **Image Embedding**: CLIP encodes all wafer map images\n",
    "2. **Text Embedding**: CLIP encodes all failure log descriptions\n",
    "3. **Query**: Can be text (\"center failures\") or reference image\n",
    "4. **Retrieval**: Find similar wafer maps (visual similarity) + relevant logs (text similarity)\n",
    "5. **LLM Analysis**: GPT-4 Vision analyzes retrieved images + logs ‚Üí root cause\n",
    "\n",
    "**Results:**\n",
    "- Find similar cases in 2 minutes vs 2 hours manual search\n",
    "- 88% diagnostic accuracy (vs 60% without visual search)\n",
    "- $20M annual savings (faster root cause ‚Üí faster yield recovery)\n",
    "\n",
    "### Implementation\n",
    "\n",
    "**CLIP Embedding:**\n",
    "```python\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Load CLIP model\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Embed wafer map image\n",
    "image = Image.open(\"wafer_map_W2024-1234.png\")\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "image_embedding = model.get_image_features(**inputs)\n",
    "\n",
    "# Embed text query\n",
    "text = \"wafer map with center failures and edge pass\"\n",
    "inputs = processor(text=text, return_tensors=\"pt\")\n",
    "text_embedding = model.get_text_features(**inputs)\n",
    "\n",
    "# Compute similarity\n",
    "similarity = torch.cosine_similarity(image_embedding, text_embedding)\n",
    "```\n",
    "\n",
    "**Multimodal Vector Database:**\n",
    "```python\n",
    "# Store in vector DB (Weaviate, Pinecone)\n",
    "# Each entry: {\n",
    "#   \"wafer_id\": \"W2024-1234\",\n",
    "#   \"image_vector\": [0.12, -0.45, ...],  # CLIP embedding\n",
    "#   \"image_url\": \"s3://wafer-maps/W2024-1234.png\",\n",
    "#   \"failure_log\": \"Center region shows...\",\n",
    "#   \"metadata\": {\"fab\": \"Fab5\", \"product\": \"GPU-A100\"}\n",
    "# }\n",
    "\n",
    "# Query: \"Show wafer maps with ring failures\"\n",
    "query_vector = get_clip_text_embedding(\"ring failures\")\n",
    "results = vector_db.search(query_vector, top_k=10)\n",
    "\n",
    "# Returns: Similar wafer maps (visual + text similarity)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Real-World Projects & Impact\n",
    "\n",
    "### üè≠ Post-Silicon Validation Projects\n",
    "\n",
    "**1. NVIDIA Wafer Map Analysis ($20M Annual Savings)**\n",
    "- **Objective**: Visual search of 100K wafer maps + failure log retrieval\n",
    "- **Data**: 100K wafer map images + failure logs + parametric data\n",
    "- **Architecture**: CLIP embeddings + Weaviate + GPT-4 Vision\n",
    "- **Features**: Image similarity, pattern matching, multimodal retrieval\n",
    "- **Metrics**: 88% diagnostic accuracy, 2-minute search vs 2 hours, 5√ó faster root cause\n",
    "- **Tech Stack**: CLIP, Weaviate, GPT-4 Vision, FastAPI, Kubernetes\n",
    "- **Impact**: $20M savings (faster root cause ‚Üí faster yield recovery)\n",
    "\n",
    "**2. AMD Thermal Imaging RAG ($12M Annual Savings)**\n",
    "- **Objective**: Identify hotspots from infrared images + power data\n",
    "- **Data**: 50K thermal images + power measurements + design specs\n",
    "- **Architecture**: CLIP + thermal pattern recognition + multimodal fusion\n",
    "- **Features**: Hotspot detection, power correlation, design recommendations\n",
    "- **Metrics**: Identify issues 10√ó faster, 92% hotspot accuracy\n",
    "- **Tech Stack**: CLIP, OpenCV, ChromaDB, Claude 3, Kubernetes\n",
    "- **Impact**: $12M power optimization savings\n",
    "\n",
    "**3. Intel PCB Layout Analysis ($15M Annual Savings)**\n",
    "- **Objective**: Correlate PCB layout issues with test failures\n",
    "- **Data**: 20K PCB layout images + signal integrity data + test failures\n",
    "- **Architecture**: CLIP + layout pattern matching + failure correlation\n",
    "- **Features**: Layout-failure correlation, design rule checks, similar case retrieval\n",
    "- **Metrics**: Design fixes 3√ó faster, 85% issue prediction accuracy\n",
    "- **Tech Stack**: CLIP, LayoutLM, Pinecone, GPT-4, Kubernetes\n",
    "- **Impact**: $15M faster TTM (identify issues in design phase)\n",
    "\n",
    "**4. Qualcomm Equipment Monitoring ($10M Annual Savings)**\n",
    "- **Objective**: Predictive maintenance from sensor images + logs\n",
    "- **Data**: 100K ATE sensor images + test logs + maintenance history\n",
    "- **Architecture**: CLIP + time-series analysis + anomaly detection\n",
    "- **Features**: Anomaly detection, predictive alerts, maintenance scheduling\n",
    "- **Metrics**: 40% downtime reduction, 90% failure prediction accuracy\n",
    "- **Tech Stack**: CLIP, InfluxDB, Prophet, FastAPI, Kubernetes\n",
    "- **Impact**: $10M equipment cost avoidance\n",
    "\n",
    "### üåê General AI/ML Projects\n",
    "\n",
    "**5. Medical Imaging + Reports RAG ($15M Value)**\n",
    "- **Objective**: X-ray/CT scan search + radiology report retrieval\n",
    "- **Data**: 1M medical images + radiology reports + diagnoses\n",
    "- **Architecture**: CLIP medical fine-tuning + HIPAA-compliant storage\n",
    "- **Features**: Image similarity, diagnosis support, evidence-based recommendations\n",
    "- **Metrics**: 85% diagnosis accuracy, reduce misdiagnosis 20%\n",
    "- **Tech Stack**: CLIP (medical fine-tuned), Milvus, GPT-4 Vision, on-prem\n",
    "- **Impact**: $15M value (better outcomes, faster diagnoses)\n",
    "\n",
    "**6. E-commerce Visual Search ($25M Revenue Increase)**\n",
    "- **Objective**: Search products by image (\"find similar dresses\")\n",
    "- **Data**: 1M product images + descriptions + reviews\n",
    "- **Architecture**: CLIP + product-specific fine-tuning + personalization\n",
    "- **Features**: Visual similarity, text-to-image search, style matching\n",
    "- **Metrics**: 40% CTR increase on visual search, 20% conversion increase\n",
    "- **Tech Stack**: CLIP (fine-tuned), Pinecone, GPT-3.5, Kubernetes\n",
    "- **Impact**: $25M revenue increase (better discovery ‚Üí more purchases)\n",
    "\n",
    "**7. Autonomous Vehicle Scene Understanding ($30M Value)**\n",
    "- **Objective**: Query dashcam footage (\"show scenes with pedestrians at crosswalks\")\n",
    "- **Data**: 100M dashcam frames + sensor data + incident reports\n",
    "- **Architecture**: CLIP + temporal analysis + object detection\n",
    "- **Features**: Scene search, incident retrieval, safety pattern analysis\n",
    "- **Metrics**: 95% scene classification accuracy, <100ms query latency\n",
    "- **Tech Stack**: CLIP, YOLO, PostgreSQL (pgvector), FastAPI\n",
    "- **Impact**: $30M value (safety improvements, incident analysis)\n",
    "\n",
    "**8. Social Media Content Moderation ($20M Cost Reduction)**\n",
    "- **Objective**: Find policy-violating images/videos at scale\n",
    "- **Data**: 1B images + policy documents + violation examples\n",
    "- **Architecture**: CLIP + policy-aware fine-tuning + active learning\n",
    "- **Features**: Visual similarity to known violations, multimodal policy matching\n",
    "- **Metrics**: 95% violation detection, 50% false positive reduction\n",
    "- **Tech Stack**: CLIP (fine-tuned), Milvus, Kubernetes, distributed processing\n",
    "- **Impact**: $20M cost reduction (automate 80% of manual review)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Key Takeaways & Next Steps\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "**1. Multimodal RAG Capabilities:**\n",
    "- **CLIP**: Unified image-text space (query with text, retrieve images)\n",
    "- **Wafer Map Analysis**: NVIDIA 88% accuracy, $20M savings\n",
    "- **Thermal Imaging**: AMD hotspot detection, $12M savings\n",
    "- **PCB Layout**: Intel design-failure correlation, $15M savings\n",
    "\n",
    "**2. Business Impact:**\n",
    "- **Post-Silicon**: NVIDIA $20M, AMD $12M, Intel $15M, Qualcomm $10M = **$57M**\n",
    "- **General AI/ML**: Medical $15M, E-commerce $25M, Autonomous $30M, Moderation $20M = **$90M**\n",
    "- **Grand Total: $147M annual value from multimodal RAG**\n",
    "\n",
    "**3. Key Technologies:**\n",
    "- CLIP for image-text embeddings\n",
    "- OCR/LayoutLM for document understanding\n",
    "- GPT-4 Vision for multimodal reasoning\n",
    "- Vector databases with image support (Weaviate, Pinecone)\n",
    "\n",
    "### Production Checklist\n",
    "\n",
    "- [ ] **Modality Analysis**: What modalities are in your docs? (images, tables, charts)\n",
    "- [ ] **CLIP Fine-Tuning**: Domain-specific (medical, satellite, manufacturing)\n",
    "- [ ] **Image Processing**: OCR, layout analysis, table extraction\n",
    "- [ ] **Vector Database**: Support for image embeddings (Weaviate, Pinecone)\n",
    "- [ ] **Multimodal LLM**: GPT-4 Vision, Claude 3, Gemini (analyze images + text)\n",
    "- [ ] **Evaluation**: Image retrieval metrics (Precision@K for images)\n",
    "- [ ] **Storage**: Efficient image storage (S3, GCS) + vector DB\n",
    "- [ ] **Latency**: Image processing adds time (OCR ~2s, CLIP ~100ms)\n",
    "\n",
    "### Common Pitfalls\n",
    "\n",
    "**1. Ignoring Images:**\n",
    "- ‚ùå Problem: Text-only RAG misses 40% of information (diagrams, charts, wafer maps)\n",
    "- ‚úÖ Solution: Extract and embed images with CLIP\n",
    "\n",
    "**2. No Image Fine-Tuning:**\n",
    "- ‚ùå Problem: Generic CLIP doesn't understand domain images (wafer maps, thermal images)\n",
    "- ‚úÖ Solution: Fine-tune CLIP on domain images (10K images, $5K cost)\n",
    "\n",
    "**3. Poor Image Quality:**\n",
    "- ‚ùå Problem: Low-resolution images (64√ó64) lose details\n",
    "- ‚úÖ Solution: Use high-res (512√ó512+), preprocess (contrast, denoising)\n",
    "\n",
    "### Resources\n",
    "\n",
    "**Models:**\n",
    "- [CLIP (OpenAI)](https://github.com/openai/CLIP)\n",
    "- [LayoutLM (Microsoft)](https://github.com/microsoft/unilm/tree/master/layoutlm)\n",
    "- GPT-4 Vision, Claude 3, Gemini\n",
    "\n",
    "**Papers:**\n",
    "- \"Learning Transferable Visual Models From Natural Language Supervision\" (CLIP, 2021)\n",
    "- \"LayoutLM: Pre-training of Text and Layout for Document Image Understanding\" (2020)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**Immediate:**\n",
    "1. **086: Fine-Tuning & PEFT** - LoRA, QLoRA for efficient model adaptation\n",
    "2. **087: AI Security & Safety** - Prompt injection, guardrails\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations!** You've mastered multimodal RAG - from CLIP embeddings to wafer map analysis to production deployment! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
